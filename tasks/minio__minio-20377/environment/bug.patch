diff --git a/internal/config/notify/help.go b/internal/config/notify/help.go
index 343f46c7b..4d07af917 100644
--- a/internal/config/notify/help.go
+++ b/internal/config/notify/help.go
@@ -274,18 +274,6 @@ var (
 			Optional:    true,
 			Type:        "number",
 		},
-		config.HelpKV{
-			Key:         target.KafkaBatchSize,
-			Description: "batch size of the events; used only when queue_dir is set",
-			Optional:    true,
-			Type:        "number",
-		},
-		config.HelpKV{
-			Key:         target.KafkaBatchCommitTimeout,
-			Description: "commit timeout set for the batch; used only when batch_size > 1",
-			Optional:    true,
-			Type:        "duration",
-		},
 	}
 
 	HelpMQTT = config.HelpKVS{
diff --git a/internal/config/notify/parse.go b/internal/config/notify/parse.go
index 0f7dc4404..75091a67c 100644
--- a/internal/config/notify/parse.go
+++ b/internal/config/notify/parse.go
@@ -374,10 +374,6 @@ var (
 			Key:   target.KafkaBatchSize,
 			Value: "0",
 		},
-		config.KV{
-			Key:   target.KafkaBatchCommitTimeout,
-			Value: "0s",
-		},
 		config.KV{
 			Key:   target.KafkaCompressionCodec,
 			Value: "",
@@ -467,23 +463,14 @@ func GetNotifyKafka(kafkaKVS map[string]config.KVS) (map[string]target.KafkaArgs
 			return nil, err
 		}
 
-		batchCommitTimeoutEnv := target.EnvKafkaBatchCommitTimeout
-		if k != config.Default {
-			batchCommitTimeoutEnv = batchCommitTimeoutEnv + config.Default + k
-		}
-		batchCommitTimeout, err := time.ParseDuration(env.Get(batchCommitTimeoutEnv, kv.Get(target.KafkaBatchCommitTimeout)))
-		if err != nil {
-			return nil, err
-		}
 		kafkaArgs := target.KafkaArgs{
-			Enable:             enabled,
-			Brokers:            brokers,
-			Topic:              env.Get(topicEnv, kv.Get(target.KafkaTopic)),
-			QueueDir:           env.Get(queueDirEnv, kv.Get(target.KafkaQueueDir)),
-			QueueLimit:         queueLimit,
-			Version:            env.Get(versionEnv, kv.Get(target.KafkaVersion)),
-			BatchSize:          uint32(batchSize),
-			BatchCommitTimeout: batchCommitTimeout,
+			Enable:     enabled,
+			Brokers:    brokers,
+			Topic:      env.Get(topicEnv, kv.Get(target.KafkaTopic)),
+			QueueDir:   env.Get(queueDirEnv, kv.Get(target.KafkaQueueDir)),
+			QueueLimit: queueLimit,
+			Version:    env.Get(versionEnv, kv.Get(target.KafkaVersion)),
+			BatchSize:  uint32(batchSize),
 		}
 
 		tlsEnableEnv := target.EnvKafkaTLS
diff --git a/internal/event/target/amqp.go b/internal/event/target/amqp.go
index c987088da..86f48f21a 100644
--- a/internal/event/target/amqp.go
+++ b/internal/event/target/amqp.go
@@ -276,8 +276,7 @@ func (target *AMQPTarget) send(eventData event.Event, ch *amqp091.Channel, confi
 // Save - saves the events to the store which will be replayed when the amqp connection is active.
 func (target *AMQPTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 	if err := target.init(); err != nil {
 		return err
@@ -303,7 +302,7 @@ func (target *AMQPTarget) SendFromStore(key store.Key) error {
 	}
 	defer ch.Close()
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and wouldve been already been sent successfully.
@@ -318,7 +317,7 @@ func (target *AMQPTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - does nothing and available for interface compatibility.
diff --git a/internal/event/target/elasticsearch.go b/internal/event/target/elasticsearch.go
index 35532334e..69116d39a 100644
--- a/internal/event/target/elasticsearch.go
+++ b/internal/event/target/elasticsearch.go
@@ -202,8 +202,7 @@ func (target *ElasticsearchTarget) isActive() (bool, error) {
 // Save - saves the events to the store if queuestore is configured, which will be replayed when the elasticsearch connection is active.
 func (target *ElasticsearchTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 	if err := target.init(); err != nil {
 		return err
@@ -279,7 +278,7 @@ func (target *ElasticsearchTarget) SendFromStore(key store.Key) error {
 		return err
 	}
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and wouldve been already been sent successfully.
@@ -297,7 +296,7 @@ func (target *ElasticsearchTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - does nothing and available for interface compatibility.
diff --git a/internal/event/target/kafka.go b/internal/event/target/kafka.go
index d6af69b8b..2ebddd321 100644
--- a/internal/event/target/kafka.go
+++ b/internal/event/target/kafka.go
@@ -43,24 +43,23 @@ import (
 
 // Kafka input constants
 const (
-	KafkaBrokers            = "brokers"
-	KafkaTopic              = "topic"
-	KafkaQueueDir           = "queue_dir"
-	KafkaQueueLimit         = "queue_limit"
-	KafkaTLS                = "tls"
-	KafkaTLSSkipVerify      = "tls_skip_verify"
-	KafkaTLSClientAuth      = "tls_client_auth"
-	KafkaSASL               = "sasl"
-	KafkaSASLUsername       = "sasl_username"
-	KafkaSASLPassword       = "sasl_password"
-	KafkaSASLMechanism      = "sasl_mechanism"
-	KafkaClientTLSCert      = "client_tls_cert"
-	KafkaClientTLSKey       = "client_tls_key"
-	KafkaVersion            = "version"
-	KafkaBatchSize          = "batch_size"
-	KafkaBatchCommitTimeout = "batch_commit_timeout"
-	KafkaCompressionCodec   = "compression_codec"
-	KafkaCompressionLevel   = "compression_level"
+	KafkaBrokers          = "brokers"
+	KafkaTopic            = "topic"
+	KafkaQueueDir         = "queue_dir"
+	KafkaQueueLimit       = "queue_limit"
+	KafkaTLS              = "tls"
+	KafkaTLSSkipVerify    = "tls_skip_verify"
+	KafkaTLSClientAuth    = "tls_client_auth"
+	KafkaSASL             = "sasl"
+	KafkaSASLUsername     = "sasl_username"
+	KafkaSASLPassword     = "sasl_password"
+	KafkaSASLMechanism    = "sasl_mechanism"
+	KafkaClientTLSCert    = "client_tls_cert"
+	KafkaClientTLSKey     = "client_tls_key"
+	KafkaVersion          = "version"
+	KafkaBatchSize        = "batch_size"
+	KafkaCompressionCodec = "compression_codec"
+	KafkaCompressionLevel = "compression_level"
 
 	EnvKafkaEnable                   = "MINIO_NOTIFY_KAFKA_ENABLE"
 	EnvKafkaBrokers                  = "MINIO_NOTIFY_KAFKA_BROKERS"
@@ -78,7 +77,6 @@ const (
 	EnvKafkaClientTLSKey             = "MINIO_NOTIFY_KAFKA_CLIENT_TLS_KEY"
 	EnvKafkaVersion                  = "MINIO_NOTIFY_KAFKA_VERSION"
 	EnvKafkaBatchSize                = "MINIO_NOTIFY_KAFKA_BATCH_SIZE"
-	EnvKafkaBatchCommitTimeout       = "MINIO_NOTIFY_KAFKA_BATCH_COMMIT_TIMEOUT"
 	EnvKafkaProducerCompressionCodec = "MINIO_NOTIFY_KAFKA_PRODUCER_COMPRESSION_CODEC"
 	EnvKafkaProducerCompressionLevel = "MINIO_NOTIFY_KAFKA_PRODUCER_COMPRESSION_LEVEL"
 )
@@ -93,15 +91,14 @@ var codecs = map[string]sarama.CompressionCodec{
 
 // KafkaArgs - Kafka target arguments.
 type KafkaArgs struct {
-	Enable             bool          `json:"enable"`
-	Brokers            []xnet.Host   `json:"brokers"`
-	Topic              string        `json:"topic"`
-	QueueDir           string        `json:"queueDir"`
-	QueueLimit         uint64        `json:"queueLimit"`
-	Version            string        `json:"version"`
-	BatchSize          uint32        `json:"batchSize"`
-	BatchCommitTimeout time.Duration `json:"batchCommitTimeout"`
-	TLS                struct {
+	Enable     bool        `json:"enable"`
+	Brokers    []xnet.Host `json:"brokers"`
+	Topic      string      `json:"topic"`
+	QueueDir   string      `json:"queueDir"`
+	QueueLimit uint64      `json:"queueLimit"`
+	Version    string      `json:"version"`
+	BatchSize  uint32      `json:"batchSize"`
+	TLS        struct {
 		Enable        bool               `json:"enable"`
 		RootCAs       *x509.CertPool     `json:"-"`
 		SkipVerify    bool               `json:"skipVerify"`
@@ -149,11 +146,6 @@ func (k KafkaArgs) Validate() error {
 			return errors.New("batch should be enabled only if queue dir is enabled")
 		}
 	}
-	if k.BatchCommitTimeout > 0 {
-		if k.QueueDir == "" || k.BatchSize <= 1 {
-			return errors.New("batch commit timeout should be set only if queue dir is enabled and batch size > 1")
-		}
-	}
 	return nil
 }
 
@@ -167,7 +159,7 @@ type KafkaTarget struct {
 	producer   sarama.SyncProducer
 	config     *sarama.Config
 	store      store.Store[event.Event]
-	batch      *store.Batch[event.Event]
+	batch      *store.Batch[string, *sarama.ProducerMessage]
 	loggerOnce logger.LogOnce
 	quitCh     chan struct{}
 }
@@ -207,11 +199,7 @@ func (target *KafkaTarget) isActive() (bool, error) {
 // Save - saves the events to the store which will be replayed when the Kafka connection is active.
 func (target *KafkaTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		if target.batch != nil {
-			return target.batch.Add(eventData)
-		}
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 	if err := target.init(); err != nil {
 		return err
@@ -232,59 +220,80 @@ func (target *KafkaTarget) send(eventData event.Event) error {
 	return err
 }
 
-// sendMultiple sends multiple messages to the kafka.
-func (target *KafkaTarget) sendMultiple(events []event.Event) error {
-	if target.producer == nil {
-		return store.ErrNotConnected
+// SendFromStore - reads an event from store and sends it to Kafka.
+func (target *KafkaTarget) SendFromStore(key store.Key) error {
+	if err := target.init(); err != nil {
+		return err
 	}
-	var msgs []*sarama.ProducerMessage
-	for _, event := range events {
-		msg, err := target.toProducerMessage(event)
-		if err != nil {
-			return err
+
+	// If batch is enabled, the event will be batched in memory
+	// and will be committed once the batch is full.
+	if target.batch != nil {
+		return target.addToBatch(key)
+	}
+
+	eventData, eErr := target.store.Get(key.Name)
+	if eErr != nil {
+		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
+		// Such events will not exist and wouldve been already been sent successfully.
+		if os.IsNotExist(eErr) {
+			return nil
 		}
-		msgs = append(msgs, msg)
+		return eErr
 	}
-	return target.producer.SendMessages(msgs)
-}
 
-// SendFromStore - reads an event from store and sends it to Kafka.
-func (target *KafkaTarget) SendFromStore(key store.Key) (err error) {
-	if err = target.init(); err != nil {
+	if err := target.send(eventData); err != nil {
+		if isKafkaConnErr(err) {
+			return store.ErrNotConnected
+		}
 		return err
 	}
-	switch {
-	case key.ItemCount == 1:
-		var event event.Event
-		event, err = target.store.Get(key)
+
+	// Delete the event from store.
+	return target.store.Del(key.Name)
+}
+
+func (target *KafkaTarget) addToBatch(key store.Key) error {
+	if target.batch.IsFull() {
+		if err := target.commitBatch(); err != nil {
+			return err
+		}
+	}
+	if _, ok := target.batch.GetByKey(key.Name); !ok {
+		eventData, err := target.store.Get(key.Name)
 		if err != nil {
-			// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
-			// Such events will not exist and wouldve been already been sent successfully.
 			if os.IsNotExist(err) {
 				return nil
 			}
 			return err
 		}
-		err = target.send(event)
-	case key.ItemCount > 1:
-		var events []event.Event
-		events, err = target.store.GetMultiple(key)
+		msg, err := target.toProducerMessage(eventData)
 		if err != nil {
-			if os.IsNotExist(err) {
-				return nil
-			}
 			return err
 		}
-		err = target.sendMultiple(events)
+		if err = target.batch.Add(key.Name, msg); err != nil {
+			return err
+		}
+	}
+	// commit the batch if the key is the last one present in the store.
+	if key.IsLast || target.batch.IsFull() {
+		return target.commitBatch()
 	}
+	return nil
+}
+
+func (target *KafkaTarget) commitBatch() error {
+	keys, msgs, err := target.batch.GetAll()
 	if err != nil {
+		return err
+	}
+	if err = target.producer.SendMessages(msgs); err != nil {
 		if isKafkaConnErr(err) {
 			return store.ErrNotConnected
 		}
 		return err
 	}
-	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.DelList(keys)
 }
 
 func (target *KafkaTarget) toProducerMessage(eventData event.Event) (*sarama.ProducerMessage, error) {
@@ -310,18 +319,7 @@ func (target *KafkaTarget) toProducerMessage(eventData event.Event) (*sarama.Pro
 func (target *KafkaTarget) Close() error {
 	close(target.quitCh)
 
-	if target.batch != nil {
-		target.batch.Close()
-	}
-
 	if target.producer != nil {
-		if target.store != nil {
-			// It is safe to abort the current transaction if
-			// queue_dir is configured
-			target.producer.AbortTxn()
-		} else {
-			target.producer.CommitTxn()
-		}
 		target.producer.Close()
 		return target.client.Close()
 	}
@@ -444,14 +442,10 @@ func NewKafkaTarget(id string, args KafkaArgs, loggerOnce logger.LogOnce) (*Kafk
 		loggerOnce: loggerOnce,
 		quitCh:     make(chan struct{}),
 	}
+
 	if target.store != nil {
 		if args.BatchSize > 1 {
-			target.batch = store.NewBatch[event.Event](store.BatchConfig[event.Event]{
-				Limit:         args.BatchSize,
-				Log:           loggerOnce,
-				Store:         queueStore,
-				CommitTimeout: args.BatchCommitTimeout,
-			})
+			target.batch = store.NewBatch[string, *sarama.ProducerMessage](args.BatchSize)
 		}
 		store.StreamItems(target.store, target, target.quitCh, target.loggerOnce)
 	}
diff --git a/internal/event/target/mqtt.go b/internal/event/target/mqtt.go
index 8f568cd3a..b390a6834 100644
--- a/internal/event/target/mqtt.go
+++ b/internal/event/target/mqtt.go
@@ -180,7 +180,7 @@ func (target *MQTTTarget) SendFromStore(key store.Key) error {
 		return err
 	}
 
-	eventData, err := target.store.Get(key)
+	eventData, err := target.store.Get(key.Name)
 	if err != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and wouldve been already been sent successfully.
@@ -195,15 +195,14 @@ func (target *MQTTTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Save - saves the events to the store if queuestore is configured, which will
 // be replayed when the mqtt connection is active.
 func (target *MQTTTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 	if err := target.init(); err != nil {
 		return err
diff --git a/internal/event/target/mysql.go b/internal/event/target/mysql.go
index acccedd89..11f419ab5 100644
--- a/internal/event/target/mysql.go
+++ b/internal/event/target/mysql.go
@@ -198,8 +198,7 @@ func (target *MySQLTarget) isActive() (bool, error) {
 // Save - saves the events to the store which will be replayed when the SQL connection is active.
 func (target *MySQLTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 	if err := target.init(); err != nil {
 		return err
@@ -274,7 +273,7 @@ func (target *MySQLTarget) SendFromStore(key store.Key) error {
 		}
 	}
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and wouldve been already been sent successfully.
@@ -292,7 +291,7 @@ func (target *MySQLTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - closes underneath connections to MySQL database.
diff --git a/internal/event/target/nats.go b/internal/event/target/nats.go
index b01aa141b..d6d781d73 100644
--- a/internal/event/target/nats.go
+++ b/internal/event/target/nats.go
@@ -299,8 +299,7 @@ func (target *NATSTarget) isActive() (bool, error) {
 // Save - saves the events to the store which will be replayed when the Nats connection is active.
 func (target *NATSTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 
 	if err := target.init(); err != nil {
@@ -354,7 +353,7 @@ func (target *NATSTarget) SendFromStore(key store.Key) error {
 		return err
 	}
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and wouldve been already been sent successfully.
@@ -368,7 +367,7 @@ func (target *NATSTarget) SendFromStore(key store.Key) error {
 		return err
 	}
 
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - closes underneath connections to NATS server.
diff --git a/internal/event/target/nsq.go b/internal/event/target/nsq.go
index a44cae108..cc95f288e 100644
--- a/internal/event/target/nsq.go
+++ b/internal/event/target/nsq.go
@@ -147,8 +147,7 @@ func (target *NSQTarget) isActive() (bool, error) {
 // Save - saves the events to the store which will be replayed when the nsq connection is active.
 func (target *NSQTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 
 	if err := target.init(); err != nil {
@@ -189,7 +188,7 @@ func (target *NSQTarget) SendFromStore(key store.Key) error {
 		return err
 	}
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and wouldve been already been sent successfully.
@@ -204,7 +203,7 @@ func (target *NSQTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - closes underneath connections to NSQD server.
diff --git a/internal/event/target/postgresql.go b/internal/event/target/postgresql.go
index 1a99db673..e46a766e3 100644
--- a/internal/event/target/postgresql.go
+++ b/internal/event/target/postgresql.go
@@ -196,8 +196,7 @@ func (target *PostgreSQLTarget) isActive() (bool, error) {
 // Save - saves the events to the store if questore is configured, which will be replayed when the PostgreSQL connection is active.
 func (target *PostgreSQLTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 
 	if err := target.init(); err != nil {
@@ -276,7 +275,7 @@ func (target *PostgreSQLTarget) SendFromStore(key store.Key) error {
 		}
 	}
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and wouldve been already been sent successfully.
@@ -294,7 +293,7 @@ func (target *PostgreSQLTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - closes underneath connections to PostgreSQL database.
diff --git a/internal/event/target/redis.go b/internal/event/target/redis.go
index 78d6c7555..b403367d6 100644
--- a/internal/event/target/redis.go
+++ b/internal/event/target/redis.go
@@ -173,8 +173,7 @@ func (target *RedisTarget) isActive() (bool, error) {
 // Save - saves the events to the store if questore is configured, which will be replayed when the redis connection is active.
 func (target *RedisTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 	if err := target.init(); err != nil {
 		return err
@@ -253,7 +252,7 @@ func (target *RedisTarget) SendFromStore(key store.Key) error {
 		target.firstPing = true
 	}
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and would've been already been sent successfully.
@@ -271,7 +270,7 @@ func (target *RedisTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - releases the resources used by the pool.
diff --git a/internal/event/target/webhook.go b/internal/event/target/webhook.go
index f892a4221..31ca09d9b 100644
--- a/internal/event/target/webhook.go
+++ b/internal/event/target/webhook.go
@@ -146,8 +146,7 @@ func (target *WebhookTarget) isActive() (bool, error) {
 // which will be replayed when the webhook connection is active.
 func (target *WebhookTarget) Save(eventData event.Event) error {
 	if target.store != nil {
-		_, err := target.store.Put(eventData)
-		return err
+		return target.store.Put(eventData)
 	}
 	if err := target.init(); err != nil {
 		return err
@@ -212,7 +211,7 @@ func (target *WebhookTarget) SendFromStore(key store.Key) error {
 		return err
 	}
 
-	eventData, eErr := target.store.Get(key)
+	eventData, eErr := target.store.Get(key.Name)
 	if eErr != nil {
 		// The last event key in a successful batch will be sent in the channel atmost once by the replayEvents()
 		// Such events will not exist and would've been already been sent successfully.
@@ -230,7 +229,7 @@ func (target *WebhookTarget) SendFromStore(key store.Key) error {
 	}
 
 	// Delete the event from store.
-	return target.store.Del(key)
+	return target.store.Del(key.Name)
 }
 
 // Close - does nothing and available for interface compatibility.
diff --git a/internal/logger/target/http/http.go b/internal/logger/target/http/http.go
index 97f01dda7..8e2a1e2f1 100644
--- a/internal/logger/target/http/http.go
+++ b/internal/logger/target/http/http.go
@@ -420,7 +420,7 @@ func (h *Target) startQueueProcessor(ctx context.Context, mainWorker bool) {
 		if !isDirQueue {
 			err = h.send(ctx, buf.Bytes(), count, h.payloadType, webhookCallTimeout)
 		} else {
-			_, err = h.store.PutMultiple(entries)
+			err = h.store.PutMultiple(entries)
 		}
 
 		if err != nil {
@@ -532,7 +532,7 @@ func New(config Config) (*Target, error) {
 // SendFromStore - reads the log from store and sends it to webhook.
 func (h *Target) SendFromStore(key store.Key) (err error) {
 	var eventData []byte
-	eventData, err = h.store.GetRaw(key)
+	eventData, err = h.store.GetRaw(key.Name)
 	if err != nil {
 		if os.IsNotExist(err) {
 			return nil
@@ -554,7 +554,7 @@ func (h *Target) SendFromStore(key store.Key) (err error) {
 	}
 
 	// Delete the event from store.
-	return h.store.Del(key)
+	return h.store.Del(key.Name)
 }
 
 // Send the log message 'entry' to the http target.
diff --git a/internal/logger/target/kafka/kafka.go b/internal/logger/target/kafka/kafka.go
index c66920419..29a0bf013 100644
--- a/internal/logger/target/kafka/kafka.go
+++ b/internal/logger/target/kafka/kafka.go
@@ -315,8 +315,7 @@ func (h *Target) IsOnline(_ context.Context) bool {
 func (h *Target) Send(ctx context.Context, entry interface{}) error {
 	if h.store != nil {
 		// save the entry to the queue store which will be replayed to the target.
-		_, err := h.store.Put(entry)
-		return err
+		return h.store.Put(entry)
 	}
 	h.logChMu.RLock()
 	defer h.logChMu.RUnlock()
@@ -345,7 +344,7 @@ func (h *Target) Send(ctx context.Context, entry interface{}) error {
 
 // SendFromStore - reads the log from store and sends it to kafka.
 func (h *Target) SendFromStore(key store.Key) (err error) {
-	auditEntry, err := h.store.Get(key)
+	auditEntry, err := h.store.Get(key.Name)
 	if err != nil {
 		if os.IsNotExist(err) {
 			return nil
@@ -359,7 +358,7 @@ func (h *Target) SendFromStore(key store.Key) (err error) {
 		return
 	}
 	// Delete the event from store.
-	return h.store.Del(key)
+	return h.store.Del(key.Name)
 }
 
 // Cancel - cancels the target
diff --git a/internal/store/batch.go b/internal/store/batch.go
index bb31135c9..cba034f4b 100644
--- a/internal/store/batch.go
+++ b/internal/store/batch.go
@@ -18,123 +18,100 @@
 package store
 
 import (
-	"context"
 	"errors"
+	"fmt"
 	"sync"
-	"time"
 )
 
 // ErrBatchFull indicates that the batch is full
 var ErrBatchFull = errors.New("batch is full")
 
-const defaultCommitTimeout = 30 * time.Second
+type key interface {
+	string | int | int64
+}
 
 // Batch represents an ordered batch
-type Batch[I any] struct {
-	items  []I
-	limit  uint32
-	store  Store[I]
-	quitCh chan struct{}
+type Batch[K key, T any] struct {
+	keys  []K
+	items map[K]T
+	limit uint32
 
 	sync.Mutex
 }
 
-// BatchConfig represents the batch config
-type BatchConfig[I any] struct {
-	Limit         uint32
-	Store         Store[I]
-	CommitTimeout time.Duration
-	Log           logger
-}
-
 // Add adds the item to the batch
-func (b *Batch[I]) Add(item I) error {
+func (b *Batch[K, T]) Add(key K, item T) error {
 	b.Lock()
 	defer b.Unlock()
 
 	if b.isFull() {
-		if b.store == nil {
-			return ErrBatchFull
-		}
-		// commit batch to store
-		if err := b.commit(); err != nil {
-			return err
-		}
+		return ErrBatchFull
+	}
+
+	if _, ok := b.items[key]; !ok {
+		b.keys = append(b.keys, key)
 	}
+	b.items[key] = item
 
-	b.items = append(b.items, item)
 	return nil
 }
 
-// Len returns the no of items in the batch
-func (b *Batch[_]) Len() int {
+// GetAll fetches the items and resets the batch
+// Returned items are not referenced by the batch
+func (b *Batch[K, T]) GetAll() (orderedKeys []K, orderedItems []T, err error) {
 	b.Lock()
 	defer b.Unlock()
 
-	return len(b.items)
-}
+	orderedKeys = append([]K(nil), b.keys...)
+	for _, key := range orderedKeys {
+		item, ok := b.items[key]
+		if !ok {
+			err = fmt.Errorf("item not found for the key: %v; should not happen;", key)
+			return
+		}
+		orderedItems = append(orderedItems, item)
+		delete(b.items, key)
+	}
 
-func (b *Batch[_]) isFull() bool {
-	return len(b.items) >= int(b.limit)
+	b.keys = b.keys[:0]
+
+	return
 }
 
-func (b *Batch[I]) commit() error {
-	switch len(b.items) {
-	case 0:
-		return nil
-	case 1:
-		_, err := b.store.Put(b.items[0])
-		return err
-	default:
-	}
-	if _, err := b.store.PutMultiple(b.items); err != nil {
-		return err
-	}
-	b.items = make([]I, 0, b.limit)
-	return nil
+// GetByKey will get the batch item by the provided key
+func (b *Batch[K, T]) GetByKey(key K) (T, bool) {
+	b.Lock()
+	defer b.Unlock()
+
+	item, ok := b.items[key]
+	return item, ok
 }
 
-// Close commits the pending items and quits the goroutines
-func (b *Batch[I]) Close() error {
-	defer func() {
-		close(b.quitCh)
-	}()
+// Len returns the no of items in the batch
+func (b *Batch[K, T]) Len() int {
+	b.Lock()
+	defer b.Unlock()
 
+	return len(b.keys)
+}
+
+// IsFull checks if the batch is full or not
+func (b *Batch[K, T]) IsFull() bool {
 	b.Lock()
 	defer b.Unlock()
-	return b.commit()
+
+	return b.isFull()
+}
+
+func (b *Batch[K, T]) isFull() bool {
+	return len(b.items) >= int(b.limit)
 }
 
 // NewBatch creates a new batch
-func NewBatch[I any](config BatchConfig[I]) *Batch[I] {
-	if config.CommitTimeout == 0 {
-		config.CommitTimeout = defaultCommitTimeout
-	}
-	quitCh := make(chan struct{})
-	batch := &Batch[I]{
-		items:  make([]I, 0, config.Limit),
-		limit:  config.Limit,
-		store:  config.Store,
-		quitCh: quitCh,
-	}
-	if batch.store != nil {
-		go func() {
-			commitTicker := time.NewTicker(config.CommitTimeout)
-			defer commitTicker.Stop()
-			for {
-				select {
-				case <-commitTicker.C:
-				case <-batch.quitCh:
-					return
-				}
-				batch.Lock()
-				err := batch.commit()
-				batch.Unlock()
-				if err != nil {
-					config.Log(context.Background(), err, "")
-				}
-			}
-		}()
+func NewBatch[K key, T any](limit uint32) *Batch[K, T] {
+	return &Batch[K, T]{
+		keys:  make([]K, 0, limit),
+		items: make(map[K]T, limit),
+		limit: limit,
 	}
-	return batch
 }
diff --git a/internal/store/batch_test.go b/internal/store/batch_test.go
index faf9d4556..db8b95dc8 100644
--- a/internal/store/batch_test.go
+++ b/internal/store/batch_test.go
@@ -18,202 +18,109 @@
 package store
 
 import (
-	"context"
+	"errors"
 	"sync"
 	"testing"
-	"time"
 )
 
-func TestBatchCommit(t *testing.T) {
-	defer func() {
-		if err := tearDownQueueStore(); err != nil {
-			t.Fatalf("Failed to tear down store; %v", err)
-		}
-	}()
-	store, err := setUpQueueStore(queueDir, 100)
-	if err != nil {
-		t.Fatalf("Failed to create a queue store; %v", err)
-	}
-
+func TestBatch(t *testing.T) {
 	var limit uint32 = 100
-
-	batch := NewBatch[TestItem](BatchConfig[TestItem]{
-		Limit:         limit,
-		Store:         store,
-		CommitTimeout: 5 * time.Minute,
-		Log: func(ctx context.Context, err error, id string, errKind ...interface{}) {
-			t.Log(err)
-		},
-	})
-	defer batch.Close()
-
+	batch := NewBatch[int, int](limit)
 	for i := 0; i < int(limit); i++ {
-		if err := batch.Add(testItem); err != nil {
+		if err := batch.Add(i, i); err != nil {
 			t.Fatalf("failed to add %v; %v", i, err)
 		}
+		if _, ok := batch.GetByKey(i); !ok {
+			t.Fatalf("failed to get the item by key %v after adding", i)
+		}
+	}
+	err := batch.Add(101, 101)
+	if err == nil || !errors.Is(err, ErrBatchFull) {
+		t.Fatalf("Expected err %v but got %v", ErrBatchFull, err)
+	}
+	if !batch.IsFull() {
+		t.Fatal("Expected batch.IsFull to be true but got false")
 	}
-
 	batchLen := batch.Len()
 	if batchLen != int(limit) {
-		t.Fatalf("Expected batch.Len() %v; but got %v", limit, batchLen)
+		t.Fatalf("expected batch length to be %v but got %v", limit, batchLen)
 	}
-
-	keys := store.List()
-	if len(keys) > 0 {
-		t.Fatalf("Expected empty store list but got len(list) %v", len(keys))
+	keys, items, err := batch.GetAll()
+	if err != nil {
+		t.Fatalf("unable to get the items from the batch; %v", err)
+	}
+	if len(items) != int(limit) {
+		t.Fatalf("Expected length of the batch items to be %v but got %v", limit, len(items))
 	}
-	if err := batch.Add(testItem); err != nil {
-		t.Fatalf("unable to add to the batch; %v", err)
+	if len(keys) != int(limit) {
+		t.Fatalf("Expected length of the batch keys to be %v but got %v", limit, len(items))
 	}
 	batchLen = batch.Len()
-	if batchLen != 1 {
-		t.Fatalf("expected batch length to be 1 but got %v", batchLen)
-	}
-	keys = store.List()
-	if len(keys) != 1 {
-		t.Fatalf("expected len(store.List())=1; but got %v", len(keys))
+	if batchLen != 0 {
+		t.Fatalf("expected batch to be empty but still left with %d items", batchLen)
 	}
-	key := keys[0]
-	if !key.Compress {
-		t.Fatal("expected key.Compress=true; but got false")
+	// Add duplicate entries
+	for i := 0; i < 10; i++ {
+		if err := batch.Add(99, 99); err != nil {
+			t.Fatalf("failed to add duplicate item %v to batch after Get; %v", i, err)
+		}
 	}
-	if key.ItemCount != int(limit) {
-		t.Fatalf("expected key.ItemCount=%d; but got %v", limit, key.ItemCount)
+	if _, ok := batch.GetByKey(99); !ok {
+		t.Fatal("failed to get the duplicxate item by key '99' after adding")
 	}
-	items, err := store.GetMultiple(key)
+	keys, items, err = batch.GetAll()
 	if err != nil {
-		t.Fatalf("unable to read key %v; %v", key.String(), err)
+		t.Fatalf("unable to get the items from the batch; %v", err)
 	}
-	if len(items) != int(limit) {
-		t.Fatalf("expected len(items)=%d; but got %v", limit, len(items))
+	if len(items) != 1 {
+		t.Fatalf("Expected length of the batch items to be 1 but got %v", len(items))
 	}
-}
-
-func TestBatchCommitOnExit(t *testing.T) {
-	defer func() {
-		if err := tearDownQueueStore(); err != nil {
-			t.Fatalf("Failed to tear down store; %v", err)
-		}
-	}()
-	store, err := setUpQueueStore(queueDir, 100)
-	if err != nil {
-		t.Fatalf("Failed to create a queue store; %v", err)
+	if len(keys) != 1 {
+		t.Fatalf("Expected length of the batch keys to be 1 but got %v", len(items))
 	}
-
-	var limit uint32 = 100
-
-	batch := NewBatch[TestItem](BatchConfig[TestItem]{
-		Limit:         limit,
-		Store:         store,
-		CommitTimeout: 5 * time.Minute,
-		Log: func(ctx context.Context, err error, id string, errKind ...interface{}) {
-			t.Log([]any{err, id, errKind}...)
-		},
-	})
-
+	// try adding again after Get.
 	for i := 0; i < int(limit); i++ {
-		if err := batch.Add(testItem); err != nil {
-			t.Fatalf("failed to add %v; %v", i, err)
+		if err := batch.Add(i, i); err != nil {
+			t.Fatalf("failed to add item %v to batch after Get; %v", i, err)
+		}
+		if _, ok := batch.GetByKey(i); !ok {
+			t.Fatalf("failed to get the item by key %v after adding", i)
 		}
-	}
-
-	batch.Close()
-	time.Sleep(1 * time.Second)
-
-	batchLen := batch.Len()
-	if batchLen != 0 {
-		t.Fatalf("Expected batch.Len()=0; but got %v", batchLen)
-	}
-
-	keys := store.List()
-	if len(keys) != 1 {
-		t.Fatalf("expected len(store.List())=1; but got %v", len(keys))
-	}
-
-	key := keys[0]
-	if !key.Compress {
-		t.Fatal("expected key.Compress=true; but got false")
-	}
-	if key.ItemCount != int(limit) {
-		t.Fatalf("expected key.ItemCount=%d; but got %v", limit, key.ItemCount)
-	}
-	items, err := store.GetMultiple(key)
-	if err != nil {
-		t.Fatalf("unable to read key %v; %v", key.String(), err)
-	}
-	if len(items) != int(limit) {
-		t.Fatalf("expected len(items)=%d; but got %v", limit, len(items))
 	}
 }
 
 func TestBatchWithConcurrency(t *testing.T) {
-	defer func() {
-		if err := tearDownQueueStore(); err != nil {
-			t.Fatalf("Failed to tear down store; %v", err)
-		}
-	}()
-	store, err := setUpQueueStore(queueDir, 100)
-	if err != nil {
-		t.Fatalf("Failed to create a queue store; %v", err)
-	}
-
 	var limit uint32 = 100
-
-	batch := NewBatch[TestItem](BatchConfig[TestItem]{
-		Limit:         limit,
-		Store:         store,
-		CommitTimeout: 5 * time.Minute,
-		Log: func(ctx context.Context, err error, id string, errKind ...interface{}) {
-			t.Log(err)
-		},
-	})
-	defer batch.Close()
+	batch := NewBatch[int, int](limit)
 
 	var wg sync.WaitGroup
 	for i := 0; i < int(limit); i++ {
 		wg.Add(1)
-		go func(key int) {
+		go func(item int) {
 			defer wg.Done()
-			if err := batch.Add(testItem); err != nil {
-				t.Errorf("failed to add item %v; %v", key, err)
+			if err := batch.Add(item, item); err != nil {
+				t.Errorf("failed to add item %v; %v", item, err)
 				return
 			}
+			if _, ok := batch.GetByKey(item); !ok {
+				t.Errorf("failed to get the item by key %v after adding", item)
+			}
 		}(i)
 	}
 	wg.Wait()
 
-	batchLen := batch.Len()
-	if batchLen != int(limit) {
-		t.Fatalf("Expected batch.Len() %v; but got %v", limit, batchLen)
-	}
-
-	keys := store.List()
-	if len(keys) > 0 {
-		t.Fatalf("Expected empty store list but got len(list) %v", len(keys))
-	}
-	if err := batch.Add(testItem); err != nil {
-		t.Fatalf("unable to add to the batch; %v", err)
-	}
-	batchLen = batch.Len()
-	if batchLen != 1 {
-		t.Fatalf("expected batch length to be 1 but got %v", batchLen)
-	}
-	keys = store.List()
-	if len(keys) != 1 {
-		t.Fatalf("expected len(store.List())=1; but got %v", len(keys))
-	}
-	key := keys[0]
-	if !key.Compress {
-		t.Fatal("expected key.Compress=true; but got false")
-	}
-	if key.ItemCount != int(limit) {
-		t.Fatalf("expected key.ItemCount=%d; but got %v", limit, key.ItemCount)
-	}
-	items, err := store.GetMultiple(key)
+	keys, items, err := batch.GetAll()
 	if err != nil {
-		t.Fatalf("unable to read key %v; %v", key.String(), err)
+		t.Fatalf("unable to get the items from the batch; %v", err)
 	}
 	if len(items) != int(limit) {
-		t.Fatalf("expected len(items)=%d; but got %v", limit, len(items))
+		t.Fatalf("expected batch length %v but got %v", limit, len(items))
+	}
+	if len(keys) != int(limit) {
+		t.Fatalf("Expected length of the batch keys to be %v but got %v", limit, len(items))
+	}
+	batchLen := batch.Len()
+	if batchLen != 0 {
+		t.Fatalf("expected batch to be empty but still left with %d items", batchLen)
 	}
 }
diff --git a/internal/store/queuestore.go b/internal/store/queuestore.go
index 1ee6278bb..002202f49 100644
--- a/internal/store/queuestore.go
+++ b/internal/store/queuestore.go
@@ -18,25 +18,24 @@
 package store
 
 import (
-	"bytes"
 	"encoding/json"
 	"errors"
+	"fmt"
 	"os"
 	"path/filepath"
 	"sort"
+	"strings"
 	"sync"
 	"time"
 
 	"github.com/google/uuid"
 	jsoniter "github.com/json-iterator/go"
-	"github.com/klauspost/compress/s2"
 	"github.com/valyala/bytebufferpool"
 )
 
 const (
 	defaultLimit = 100000 // Default store limit.
 	defaultExt   = ".unknown"
-	compressExt  = ".snappy"
 )
 
 // errLimitExceeded error is sent when the maximum limit is reached.
@@ -84,12 +83,18 @@ func (store *QueueStore[_]) Open() error {
 		return err
 	}
 
+	// Truncate entries.
+	if uint64(len(files)) > store.entryLimit {
+		files = files[:store.entryLimit]
+	}
+
 	for _, file := range files {
 		if file.IsDir() {
 			continue
 		}
+		key := strings.TrimSuffix(file.Name(), store.fileExt)
 		if fi, err := file.Info(); err == nil {
-			store.entries[file.Name()] = fi.ModTime().UnixNano()
+			store.entries[key] = fi.ModTime().UnixNano()
 		}
 	}
 
@@ -102,138 +107,96 @@ func (store *QueueStore[_]) Delete() error {
 }
 
 // PutMultiple - puts an item to the store.
-func (store *QueueStore[I]) PutMultiple(items []I) (Key, error) {
+func (store *QueueStore[I]) PutMultiple(item []I) error {
 	// Generate a new UUID for the key.
-	uid, err := uuid.NewRandom()
+	key, err := uuid.NewRandom()
 	if err != nil {
-		return Key{}, err
+		return err
 	}
 
 	store.Lock()
 	defer store.Unlock()
 	if uint64(len(store.entries)) >= store.entryLimit {
-		return Key{}, errLimitExceeded
+		return errLimitExceeded
 	}
-	key := Key{
-		Name:      uid.String(),
-		ItemCount: len(items),
-		Compress:  true,
-		Extension: store.fileExt,
-	}
-	return key, store.multiWrite(key, items)
+	return store.multiWrite(fmt.Sprintf("%d:%s", len(item), key.String()), item)
 }
 
 // multiWrite - writes an item to the directory.
-func (store *QueueStore[I]) multiWrite(key Key, items []I) (err error) {
+func (store *QueueStore[I]) multiWrite(key string, item []I) error {
 	buf := bytebufferpool.Get()
 	defer bytebufferpool.Put(buf)
 
 	enc := jsoniter.ConfigCompatibleWithStandardLibrary.NewEncoder(buf)
 
-	for i := range items {
-		if err = enc.Encode(items[i]); err != nil {
+	for i := range item {
+		err := enc.Encode(item[i])
+		if err != nil {
 			return err
 		}
 	}
+	b := buf.Bytes()
 
-	path := filepath.Join(store.directory, key.String())
-	if key.Compress {
-		err = os.WriteFile(path, s2.Encode(nil, buf.Bytes()), os.FileMode(0o770))
-	} else {
-		err = os.WriteFile(path, buf.Bytes(), os.FileMode(0o770))
-	}
-
+	path := filepath.Join(store.directory, key+store.fileExt)
+	err := os.WriteFile(path, b, os.FileMode(0o770))
 	buf.Reset()
 	if err != nil {
 		return err
 	}
 
 	// Increment the item count.
-	store.entries[key.String()] = time.Now().UnixNano()
+	store.entries[key] = time.Now().UnixNano()
 
-	return
+	return nil
 }
 
 // write - writes an item to the directory.
-func (store *QueueStore[I]) write(key Key, item I) error {
+func (store *QueueStore[I]) write(key string, item I) error {
 	// Marshalls the item.
 	eventData, err := json.Marshal(item)
 	if err != nil {
 		return err
 	}
-	return store.writeBytes(key, eventData)
-}
-
-// writeBytes - writes bytes to the directory.
-func (store *QueueStore[I]) writeBytes(key Key, b []byte) (err error) {
-	path := filepath.Join(store.directory, key.String())
-
-	if key.Compress {
-		err = os.WriteFile(path, s2.Encode(nil, b), os.FileMode(0o770))
-	} else {
-		err = os.WriteFile(path, b, os.FileMode(0o770))
-	}
 
-	if err != nil {
+	path := filepath.Join(store.directory, key+store.fileExt)
+	if err := os.WriteFile(path, eventData, os.FileMode(0o770)); err != nil {
 		return err
 	}
+
 	// Increment the item count.
-	store.entries[key.String()] = time.Now().UnixNano()
+	store.entries[key] = time.Now().UnixNano()
+
 	return nil
 }
 
 // Put - puts an item to the store.
-func (store *QueueStore[I]) Put(item I) (Key, error) {
-	store.Lock()
-	defer store.Unlock()
-	if uint64(len(store.entries)) >= store.entryLimit {
-		return Key{}, errLimitExceeded
-	}
-	// Generate a new UUID for the key.
-	uid, err := uuid.NewRandom()
-	if err != nil {
-		return Key{}, err
-	}
-	key := Key{
-		Name:      uid.String(),
-		Extension: store.fileExt,
-		ItemCount: 1,
-	}
-	return key, store.write(key, item)
-}
-
-// PutRaw - puts the raw bytes to the store
-func (store *QueueStore[I]) PutRaw(b []byte) (Key, error) {
+func (store *QueueStore[I]) Put(item I) error {
 	store.Lock()
 	defer store.Unlock()
 	if uint64(len(store.entries)) >= store.entryLimit {
-		return Key{}, errLimitExceeded
+		return errLimitExceeded
 	}
 	// Generate a new UUID for the key.
-	uid, err := uuid.NewRandom()
+	key, err := uuid.NewRandom()
 	if err != nil {
-		return Key{}, err
-	}
-	key := Key{
-		Name:      uid.String(),
-		Extension: store.fileExt,
+		return err
 	}
-	return key, store.writeBytes(key, b)
+	return store.write(key.String(), item)
 }
 
 // GetRaw - gets an item from the store.
-func (store *QueueStore[I]) GetRaw(key Key) (raw []byte, err error) {
+func (store *QueueStore[I]) GetRaw(key string) (raw []byte, err error) {
 	store.RLock()
 
 	defer func(store *QueueStore[I]) {
 		store.RUnlock()
-		if err != nil && !os.IsNotExist(err) {
+		if err != nil {
 			// Upon error we remove the entry.
 			store.Del(key)
 		}
 	}(store)
 
-	raw, err = os.ReadFile(filepath.Join(store.directory, key.String()))
+	raw, err = os.ReadFile(filepath.Join(store.directory, key+store.fileExt))
 	if err != nil {
 		return
 	}
@@ -246,19 +209,19 @@ func (store *QueueStore[I]) GetRaw(key Key) (raw []byte, err error) {
 }
 
 // Get - gets an item from the store.
-func (store *QueueStore[I]) Get(key Key) (item I, err error) {
+func (store *QueueStore[I]) Get(key string) (item I, err error) {
 	store.RLock()
 
 	defer func(store *QueueStore[I]) {
 		store.RUnlock()
-		if err != nil && !os.IsNotExist(err) {
+		if err != nil {
 			// Upon error we remove the entry.
 			store.Del(key)
 		}
 	}(store)
 
 	var eventData []byte
-	eventData, err = os.ReadFile(filepath.Join(store.directory, key.String()))
+	eventData, err = os.ReadFile(filepath.Join(store.directory, key+store.fileExt))
 	if err != nil {
 		return item, err
 	}
@@ -274,50 +237,26 @@ func (store *QueueStore[I]) Get(key Key) (item I, err error) {
 	return item, nil
 }
 
-// GetMultiple will read the multi payload file and fetch the items
-func (store *QueueStore[I]) GetMultiple(key Key) (items []I, err error) {
-	store.RLock()
-
-	defer func(store *QueueStore[I]) {
-		store.RUnlock()
-		if err != nil && !os.IsNotExist(err) {
-			// Upon error we remove the entry.
-			store.Del(key)
-		}
-	}(store)
-
-	raw, err := os.ReadFile(filepath.Join(store.directory, key.String()))
-	if err != nil {
-		return
-	}
+// Del - Deletes an entry from the store.
+func (store *QueueStore[_]) Del(key string) error {
+	store.Lock()
+	defer store.Unlock()
+	return store.del(key)
+}
 
-	var decoder *jsoniter.Decoder
-	if key.Compress {
-		decodedBytes, err := s2.Decode(nil, raw)
-		if err != nil {
-			return nil, err
-		}
-		decoder = jsoniter.ConfigCompatibleWithStandardLibrary.NewDecoder(bytes.NewReader(decodedBytes))
-	} else {
-		decoder = jsoniter.ConfigCompatibleWithStandardLibrary.NewDecoder(bytes.NewReader(raw))
-	}
+// DelList - Deletes a list of entries from the store.
+// Returns an error even if one key fails to be deleted.
+func (store *QueueStore[_]) DelList(keys []string) error {
+	store.Lock()
+	defer store.Unlock()
 
-	for decoder.More() {
-		var item I
-		if err := decoder.Decode(&item); err != nil {
-			return nil, err
+	for _, key := range keys {
+		if err := store.del(key); err != nil {
+			return err
 		}
-		items = append(items, item)
 	}
 
-	return
-}
-
-// Del - Deletes an entry from the store.
-func (store *QueueStore[_]) Del(key Key) error {
-	store.Lock()
-	defer store.Unlock()
-	return store.del(key)
+	return nil
 }
 
 // Len returns the entry count.
@@ -329,35 +268,30 @@ func (store *QueueStore[_]) Len() int {
 }
 
 // lockless call
-func (store *QueueStore[_]) del(key Key) error {
-	err := os.Remove(filepath.Join(store.directory, key.String()))
+func (store *QueueStore[_]) del(key string) error {
+	err := os.Remove(filepath.Join(store.directory, key+store.fileExt))
 
 	// Delete as entry no matter the result
-	delete(store.entries, key.String())
+	delete(store.entries, key)
 
 	return err
 }
 
 // List - lists all files registered in the store.
-func (store *QueueStore[_]) List() (keys []Key) {
+func (store *QueueStore[_]) List() ([]string, error) {
 	store.RLock()
-	defer store.RUnlock()
-
-	entries := make([]string, 0, len(store.entries))
-	for entry := range store.entries {
-		entries = append(entries, entry)
+	l := make([]string, 0, len(store.entries))
+	for k := range store.entries {
+		l = append(l, k)
 	}
 
 	// Sort entries...
-	sort.Slice(entries, func(i, j int) bool {
-		return store.entries[entries[i]] < store.entries[entries[j]]
+	sort.Slice(l, func(i, j int) bool {
+		return store.entries[l[i]] < store.entries[l[j]]
 	})
+	store.RUnlock()
 
-	for i := range entries {
-		keys = append(keys, parseKey(entries[i]))
-	}
-
-	return keys
+	return l, nil
 }
 
 // list will read all entries from disk.
@@ -384,3 +318,9 @@ func (store *QueueStore[_]) list() ([]os.DirEntry, error) {
 
 	return files, nil
 }
+
+// Extension will return the file extension used
+// for the items stored in the queue.
+func (store *QueueStore[_]) Extension() string {
+	return store.fileExt
+}
diff --git a/internal/store/queuestore_test.go b/internal/store/queuestore_test.go
index bcb47049d..680cb177b 100644
--- a/internal/store/queuestore_test.go
+++ b/internal/store/queuestore_test.go
@@ -18,10 +18,10 @@
 package store
 
 import (
-	"fmt"
 	"os"
 	"path/filepath"
 	"reflect"
+	"strings"
 	"testing"
 )
 
@@ -66,14 +66,17 @@ func TestQueueStorePut(t *testing.T) {
 	}
 	// Put 100 items.
 	for i := 0; i < 100; i++ {
-		if _, err := store.Put(testItem); err != nil {
+		if err := store.Put(testItem); err != nil {
 			t.Fatal("Failed to put to queue store ", err)
 		}
 	}
 	// Count the items.
-	keys := store.List()
-	if len(keys) != 100 {
-		t.Fatalf("List() Expected: 100, got %d", len(keys))
+	names, err := store.List()
+	if err != nil {
+		t.Fatal(err)
+	}
+	if len(names) != 100 {
+		t.Fatalf("List() Expected: 100, got %d", len(names))
 	}
 }
 
@@ -90,15 +93,18 @@ func TestQueueStoreGet(t *testing.T) {
 	}
 	// Put 10 items
 	for i := 0; i < 10; i++ {
-		if _, err := store.Put(testItem); err != nil {
+		if err := store.Put(testItem); err != nil {
 			t.Fatal("Failed to put to queue store ", err)
 		}
 	}
-	itemKeys := store.List()
+	itemKeys, err := store.List()
+	if err != nil {
+		t.Fatal(err)
+	}
 	// Get 10 items.
 	if len(itemKeys) == 10 {
 		for _, key := range itemKeys {
-			item, eErr := store.Get(key)
+			item, eErr := store.Get(strings.TrimSuffix(key, testItemExt))
 			if eErr != nil {
 				t.Fatal("Failed to Get the item from the queue store ", eErr)
 			}
@@ -124,15 +130,18 @@ func TestQueueStoreDel(t *testing.T) {
 	}
 	// Put 20 items.
 	for i := 0; i < 20; i++ {
-		if _, err := store.Put(testItem); err != nil {
+		if err := store.Put(testItem); err != nil {
 			t.Fatal("Failed to put to queue store ", err)
 		}
 	}
-	itemKeys := store.List()
+	itemKeys, err := store.List()
+	if err != nil {
+		t.Fatal(err)
+	}
 	// Remove all the items.
 	if len(itemKeys) == 20 {
 		for _, key := range itemKeys {
-			err := store.Del(key)
+			err := store.Del(strings.TrimSuffix(key, testItemExt))
 			if err != nil {
 				t.Fatal("queue store Del failed with ", err)
 			}
@@ -141,9 +150,12 @@ func TestQueueStoreDel(t *testing.T) {
 		t.Fatalf("List() Expected: 20, got %d", len(itemKeys))
 	}
 
-	keys := store.List()
-	if len(keys) != 0 {
-		t.Fatalf("List() Expected: 0, got %d", len(keys))
+	names, err := store.List()
+	if err != nil {
+		t.Fatal(err)
+	}
+	if len(names) != 0 {
+		t.Fatalf("List() Expected: 0, got %d", len(names))
 	}
 }
 
@@ -160,12 +172,12 @@ func TestQueueStoreLimit(t *testing.T) {
 		t.Fatal("Failed to create a queue store ", err)
 	}
 	for i := 0; i < 5; i++ {
-		if _, err := store.Put(testItem); err != nil {
+		if err := store.Put(testItem); err != nil {
 			t.Fatal("Failed to put to queue store ", err)
 		}
 	}
 	// Should not allow 6th Put.
-	if _, err := store.Put(testItem); err == nil {
+	if err := store.Put(testItem); err == nil {
 		t.Fatalf("Expected to fail with %s, but passes", errLimitExceeded)
 	}
 }
@@ -182,15 +194,18 @@ func TestQueueStoreListN(t *testing.T) {
 		t.Fatal("Failed to create a queue store ", err)
 	}
 	for i := 0; i < 10; i++ {
-		if _, err := store.Put(testItem); err != nil {
+		if err := store.Put(testItem); err != nil {
 			t.Fatal("Failed to put to queue store ", err)
 		}
 	}
 	// Should return all the item keys in the store.
-	keys := store.List()
+	names, err := store.List()
+	if err != nil {
+		t.Fatal(err)
+	}
 
-	if len(keys) != 10 {
-		t.Fatalf("List() Expected: 10, got %d", len(keys))
+	if len(names) != 10 {
+		t.Fatalf("List() Expected: 10, got %d", len(names))
 	}
 
 	// re-open
@@ -198,154 +213,28 @@ func TestQueueStoreListN(t *testing.T) {
 	if err != nil {
 		t.Fatal("Failed to create a queue store ", err)
 	}
-	keys = store.List()
+	names, err = store.List()
+	if err != nil {
+		t.Fatal(err)
+	}
 
-	if len(keys) != 10 {
-		t.Fatalf("List() Expected: 10, got %d", len(keys))
+	if len(names) != 10 {
+		t.Fatalf("List() Expected: 10, got %d", len(names))
 	}
-	if len(keys) != store.Len() {
-		t.Fatalf("List() Expected: 10, got %d", len(keys))
+	if len(names) != store.Len() {
+		t.Fatalf("List() Expected: 10, got %d", len(names))
 	}
 
 	// Delete all
-	for _, key := range keys {
+	for _, key := range names {
 		err := store.Del(key)
 		if err != nil {
 			t.Fatal(err)
 		}
 	}
 	// Re-list
-	keys = store.List()
-	if len(keys) > 0 || err != nil {
-		t.Fatalf("Expected List() to return empty list and no error, got %v err: %v", keys, err)
-	}
-}
-
-func TestMultiplePutGets(t *testing.T) {
-	defer func() {
-		if err := tearDownQueueStore(); err != nil {
-			t.Fatalf("Failed to tear down store; %v", err)
-		}
-	}()
-	store, err := setUpQueueStore(queueDir, 10)
-	if err != nil {
-		t.Fatalf("Failed to create a queue store; %v", err)
-	}
-	// TestItem{Name: "test-item", Property: "property"}
-	var items []TestItem
-	for i := 0; i < 10; i++ {
-		items = append(items, TestItem{
-			Name:     fmt.Sprintf("test-item-%d", i),
-			Property: "property",
-		})
-	}
-
-	if _, err := store.PutMultiple(items); err != nil {
-		t.Fatalf("failed to put multiple; %v", err)
-	}
-
-	keys := store.List()
-	if len(keys) != 1 {
-		t.Fatalf("expected len(keys)=1, but found %d", len(keys))
-	}
-
-	key := keys[0]
-	if !key.Compress {
-		t.Fatal("expected the item to be compressed")
-	}
-	if key.ItemCount != 10 {
-		t.Fatalf("expected itemcount=10 but found %v", key.ItemCount)
-	}
-
-	resultItems, err := store.GetMultiple(key)
-	if err != nil {
-		t.Fatalf("unable to get multiple items; %v", err)
-	}
-
-	if !reflect.DeepEqual(resultItems, items) {
-		t.Fatalf("expected item list: %v; but got %v", items, resultItems)
-	}
-
-	if err := store.Del(key); err != nil {
-		t.Fatalf("unable to Del; %v", err)
-	}
-
-	// Re-list
-	keys = store.List()
-	if len(keys) > 0 || err != nil {
-		t.Fatalf("Expected List() to return empty list and no error, got %v err: %v", keys, err)
-	}
-}
-
-func TestMixedPutGets(t *testing.T) {
-	defer func() {
-		if err := tearDownQueueStore(); err != nil {
-			t.Fatalf("Failed to tear down store; %v", err)
-		}
-	}()
-	store, err := setUpQueueStore(queueDir, 10)
-	if err != nil {
-		t.Fatalf("Failed to create a queue store; %v", err)
-	}
-	// TestItem{Name: "test-item", Property: "property"}
-	var items []TestItem
-	for i := 0; i < 5; i++ {
-		items = append(items, TestItem{
-			Name:     fmt.Sprintf("test-item-%d", i),
-			Property: "property",
-		})
-	}
-	if _, err := store.PutMultiple(items); err != nil {
-		t.Fatalf("failed to put multiple; %v", err)
-	}
-
-	for i := 5; i < 10; i++ {
-		item := TestItem{
-			Name:     fmt.Sprintf("test-item-%d", i),
-			Property: "property",
-		}
-		if _, err := store.Put(item); err != nil {
-			t.Fatalf("unable to store.Put(); %v", err)
-		}
-		items = append(items, item)
-	}
-
-	keys := store.List()
-	if len(keys) != 6 {
-		// 1 multiple + 5 single PUTs
-		t.Fatalf("expected len(keys)=6, but found %d", len(keys))
-	}
-
-	var resultItems []TestItem
-	for _, key := range keys {
-		if key.ItemCount > 1 {
-			items, err := store.GetMultiple(key)
-			if err != nil {
-				t.Fatalf("unable to get multiple items; %v", err)
-			}
-			resultItems = append(resultItems, items...)
-			continue
-		}
-		item, err := store.Get(key)
-		if err != nil {
-			t.Fatalf("unable to get item; %v", err)
-		}
-		resultItems = append(resultItems, item)
-	}
-
-	if !reflect.DeepEqual(resultItems, items) {
-		t.Fatalf("expected item list: %v; but got %v", items, resultItems)
-	}
-
-	// Delete all
-	for _, key := range keys {
-		if err := store.Del(key); err != nil {
-			t.Fatalf("unable to Del; %v", err)
-		}
-	}
-	// Re-list
-	keys = store.List()
-	if len(keys) > 0 || err != nil {
-		t.Fatalf("Expected List() to return empty list and no error, got %v err: %v", keys, err)
+	lst, err := store.List()
+	if len(lst) > 0 || err != nil {
+		t.Fatalf("Expected List() to return empty list and no error, got %v err: %v", lst, err)
 	}
 }
diff --git a/internal/store/store.go b/internal/store/store.go
index fcd76dc60..a72721856 100644
--- a/internal/store/store.go
+++ b/internal/store/store.go
@@ -21,7 +21,6 @@ import (
 	"context"
 	"errors"
 	"fmt"
-	"strconv"
 	"strings"
 	"time"
 
@@ -45,64 +44,23 @@ type Target interface {
 
 // Store - Used to persist items.
 type Store[I any] interface {
-	Put(item I) (Key, error)
-	PutMultiple(item []I) (Key, error)
-	Get(key Key) (I, error)
-	GetMultiple(key Key) ([]I, error)
-	GetRaw(key Key) ([]byte, error)
-	PutRaw(b []byte) (Key, error)
+	Put(item I) error
+	PutMultiple(item []I) error
+	Get(key string) (I, error)
+	GetRaw(key string) ([]byte, error)
 	Len() int
-	List() []Key
-	Del(key Key) error
+	List() ([]string, error)
+	Del(key string) error
+	DelList(key []string) error
 	Open() error
 	Delete() error
+	Extension() string
 }
 
 // Key denotes the key present in the store.
 type Key struct {
-	Name      string
-	Compress  bool
-	Extension string
-	ItemCount int
-}
-
-// String returns the filepath name
-func (k Key) String() string {
-	keyStr := k.Name
-	if k.ItemCount > 1 {
-		keyStr = fmt.Sprintf("%d:%s", k.ItemCount, k.Name)
-	}
-	return keyStr + k.Extension + func() string {
-		if k.Compress {
-			return compressExt
-		}
-		return ""
-	}()
-}
-
-func getItemCount(k string) (count int, err error) {
-	count = 1
-	v := strings.Split(k, ":")
-	if len(v) == 2 {
-		return strconv.Atoi(v[0])
-	}
-	return
-}
-
-func parseKey(k string) (key Key) {
-	key.Name = k
-	if strings.HasSuffix(k, compressExt) {
-		key.Compress = true
-		key.Name = strings.TrimSuffix(key.Name, compressExt)
-	}
-	if key.ItemCount, _ = getItemCount(k); key.ItemCount > 1 {
-		key.Name = strings.TrimPrefix(key.Name, fmt.Sprintf("%d:", key.ItemCount))
-	}
-	if vals := strings.Split(key.Name, "."); len(vals) == 2 {
-		key.Extension = "." + vals[1]
-		key.Name = strings.TrimSuffix(key.Name, key.Extension)
-	}
-	return
+	Name   string
+	IsLast bool
 }
 
 // replayItems - Reads the items from the store and replays.
@@ -116,12 +74,18 @@ func replayItems[I any](store Store[I], doneCh <-chan struct{}, log logger, id s
 		defer retryTicker.Stop()
 
 		for {
-			for _, key := range store.List() {
-				select {
-				case keyCh <- key:
-				// Get next key.
-				case <-doneCh:
-					return
+			names, err := store.List()
+			if err != nil {
+				log(context.Background(), fmt.Errorf("store.List() failed with: %w", err), id)
+			} else {
+				keyCount := len(names)
+				for i, name := range names {
+					select {
+					case keyCh <- Key{strings.TrimSuffix(name, store.Extension()), keyCount == i+1}:
+					// Get next key.
+					case <-doneCh:
+						return
+					}
 				}
 			}
 
@@ -150,7 +114,7 @@ func sendItems(target Target, keyCh <-chan Key, doneCh <-chan struct{}, logger l
 
 			logger(
 				context.Background(),
-				fmt.Errorf("unable to send log entry to '%s' err '%w'", target.Name(), err),
+				fmt.Errorf("unable to send webhook log entry to '%s' err '%w'", target.Name(), err),
 				target.Name(),
 			)
 
diff --git a/internal/store/store_test.go b/internal/store/store_test.go
deleted file mode 100644
index 4c05f3d73..000000000
--- a/internal/store/store_test.go
+++ /dev/null
@@ -1,146 +0,0 @@
-// Copyright (c) 2015-2024 MinIO, Inc.
-//
-// This file is part of MinIO Object Storage stack
-//
-// This program is free software: you can redistribute it and/or modify
-// it under the terms of the GNU Affero General Public License as published by
-// the Free Software Foundation, either version 3 of the License, or
-// (at your option) any later version.
-//
-// This program is distributed in the hope that it will be useful
-// but WITHOUT ANY WARRANTY; without even the implied warranty of
-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-// GNU Affero General Public License for more details.
-//
-// You should have received a copy of the GNU Affero General Public License
-// along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-package store
-
-import (
-	"testing"
-)
-
-func TestKeyString(t *testing.T) {
-	testCases := []struct {
-		key            Key
-		expectedString string
-	}{
-		{
-			key: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Extension: ".event",
-			},
-			expectedString: "01894394-d046-4783-ba0d-f1c6885790dc.event",
-		},
-		{
-			key: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Compress:  true,
-				Extension: ".event",
-				ItemCount: 100,
-			},
-			expectedString: "100:01894394-d046-4783-ba0d-f1c6885790dc.event.snappy",
-		},
-		{
-			key: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Extension: ".event",
-				ItemCount: 100,
-			},
-			expectedString: "100:01894394-d046-4783-ba0d-f1c6885790dc.event",
-		},
-		{
-			key: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Compress:  true,
-				Extension: ".event",
-				ItemCount: 1,
-			},
-			expectedString: "01894394-d046-4783-ba0d-f1c6885790dc.event.snappy",
-		},
-		{
-			key: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Extension: ".event",
-				ItemCount: 1,
-			},
-			expectedString: "01894394-d046-4783-ba0d-f1c6885790dc.event",
-		},
-	}
-
-	for i, testCase := range testCases {
-		if testCase.expectedString != testCase.key.String() {
-			t.Fatalf("case[%v]: key.String() Expected: %s, got %s", i, testCase.expectedString, testCase.key.String())
-		}
-	}
-}
-
-func TestParseKey(t *testing.T) {
-	testCases := []struct {
-		str         string
-		expectedKey Key
-	}{
-		{
-			str: "01894394-d046-4783-ba0d-f1c6885790dc.event",
-			expectedKey: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Extension: ".event",
-				ItemCount: 1,
-			},
-		},
-		{
-			str: "100:01894394-d046-4783-ba0d-f1c6885790dc.event.snappy",
-			expectedKey: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Compress:  true,
-				Extension: ".event",
-				ItemCount: 100,
-			},
-		},
-		{
-			str: "100:01894394-d046-4783-ba0d-f1c6885790dc.event",
-			expectedKey: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Extension: ".event",
-				ItemCount: 100,
-			},
-		},
-		{
-			str: "01894394-d046-4783-ba0d-f1c6885790dc.event.snappy",
-			expectedKey: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Compress:  true,
-				Extension: ".event",
-				ItemCount: 1,
-			},
-		},
-		{
-			str: "01894394-d046-4783-ba0d-f1c6885790dc.event",
-			expectedKey: Key{
-				Name:      "01894394-d046-4783-ba0d-f1c6885790dc",
-				Extension: ".event",
-				ItemCount: 1,
-			},
-		},
-	}
-
-	for i, testCase := range testCases {
-		key := parseKey(testCase.str)
-		if testCase.expectedKey.Name != key.Name {
-			t.Fatalf("case[%v]: Expected key.Name: %v, got %v", i, testCase.expectedKey.Name, key.Name)
-		}
-		if testCase.expectedKey.Compress != key.Compress {
-			t.Fatalf("case[%v]: Expected key.Compress: %v, got %v", i, testCase.expectedKey.Compress, key.Compress)
-		}
-		if testCase.expectedKey.Extension != key.Extension {
-			t.Fatalf("case[%v]: Expected key.Extension: %v, got %v", i, testCase.expectedKey.Extension, key.Extension)
-		}
-		if testCase.expectedKey.ItemCount != key.ItemCount {
-			t.Fatalf("case[%v]: Expected key.ItemCount: %v, got %v", i, testCase.expectedKey.ItemCount, key.ItemCount)
-		}
-		if testCase.expectedKey.String() != key.String() {
-			t.Fatalf("case[%v]: Expected key.String(): %v, got %v", i, testCase.expectedKey.String(), key.String())
-		}
-	}
-}
