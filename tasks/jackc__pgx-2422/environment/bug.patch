diff --git a/batch_test.go b/batch_test.go
index df205ae3..d49b4e86 100644
--- a/batch_test.go
+++ b/batch_test.go
@@ -1043,12 +1043,15 @@ func TestSendBatchStatementTimeout(t *testing.T) {
 		assert.NoError(t, err)
 
 		// get pg_sleep results
-		rows, _ := br.Query()
+		rows, err := br.Query()
+		assert.NoError(t, err)
 
 		// Consume rows and check error
-		rows.Close()
+		for rows.Next() {
+		}
 		err = rows.Err()
 		assert.ErrorContains(t, err, "(SQLSTATE 57014)")
+		rows.Close()
 
 		// The last error should be repeated when closing the batch
 		err = br.Close()
@@ -1127,43 +1130,6 @@ func TestSendBatchHandlesTimeoutBetweenParseAndDescribe(t *testing.T) {
 	})
 }
 
-func TestBatchNetworkUsage(t *testing.T) {
-	t.Parallel()
-
-	config := mustParseConfig(t, os.Getenv("PGX_TEST_DATABASE"))
-	config.DefaultQueryExecMode = pgx.QueryExecModeCacheStatement
-	var counterConn *byteCounterConn
-	config.AfterNetConnect = func(ctx context.Context, config *pgconn.Config, conn net.Conn) (net.Conn, error) {
-		counterConn = &byteCounterConn{conn: conn}
-		return counterConn, nil
-	}
-
-	conn := mustConnect(t, config)
-	defer closeConn(t, conn)
-
-	pgxtest.SkipCockroachDB(t, conn, "Server uses different number of bytes for same operations")
-
-	counterConn.bytesWritten = 0
-	counterConn.bytesRead = 0
-
-	batch := &pgx.Batch{}
-
-	for range 10 {
-		batch.Queue(
-			"select n, 'Adam', 'Smith ' || n, 'male', '1952-06-16'::date, 258, 72, '{foo,bar,baz}'::text[], '2001-01-28 01:02:03-05'::timestamptz from generate_series(100001, 100000 + $1) n",
-			1,
-		)
-	}
-
-	err := conn.SendBatch(context.Background(), batch).Close()
-	require.NoError(t, err)
-
-	assert.Equal(t, 1736, counterConn.bytesRead)
-	assert.Equal(t, 1408, counterConn.bytesWritten)
-
-	ensureConnValid(t, conn)
-}
-
 func ExampleConn_SendBatch() {
 	ctx, cancel := context.WithTimeout(context.Background(), 120*time.Second)
 	defer cancel()
diff --git a/bench_test.go b/bench_test.go
index 9b3fa5c6..f2625118 100644
--- a/bench_test.go
+++ b/bench_test.go
@@ -158,41 +158,6 @@ func BenchmarkMinimalPgConnPreparedSelect(b *testing.B) {
 	}
 }
 
-func BenchmarkMinimalPgConnPreparedStatementDescriptionSelect(b *testing.B) {
-	conn := mustConnect(b, mustParseConfig(b, os.Getenv("PGX_TEST_DATABASE")))
-	defer closeConn(b, conn)
-
-	pgConn := conn.PgConn()
-
-	psd, err := pgConn.Prepare(context.Background(), "ps1", "select $1::int8", nil)
-	if err != nil {
-		b.Fatal(err)
-	}
-
-	encodedBytes := make([]byte, 8)
-
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-
-		rr := pgConn.ExecStatement(context.Background(), psd, [][]byte{encodedBytes}, []int16{1}, []int16{1})
-		if err != nil {
-			b.Fatal(err)
-		}
-
-		for rr.NextRow() {
-			for i := range rr.Values() {
-				if !bytes.Equal(rr.Values()[0], encodedBytes) {
-					b.Fatalf("unexpected values: %s %s", rr.Values()[i], encodedBytes)
-				}
-			}
-		}
-		_, err = rr.Close()
-		if err != nil {
-			b.Fatal(err)
-		}
-	}
-}
-
 func BenchmarkPointerPointerWithNullValues(b *testing.B) {
 	conn := mustConnect(b, mustParseConfig(b, os.Getenv("PGX_TEST_DATABASE")))
 	defer closeConn(b, conn)
@@ -1298,51 +1263,6 @@ func BenchmarkSelectRowsPgConnExecPrepared(b *testing.B) {
 	}
 }
 
-func BenchmarkSelectRowsPgConnExecStatement(b *testing.B) {
-	conn := mustConnectString(b, os.Getenv("PGX_TEST_DATABASE"))
-	defer closeConn(b, conn)
-
-	rowCounts := getSelectRowsCounts(b)
-
-	psd, err := conn.PgConn().Prepare(context.Background(), "ps1", "select n, 'Adam', 'Smith ' || n, 'male', '1952-06-16'::date, 258, 72, '{foo,bar,baz}'::text[], '2001-01-28 01:02:03-05'::timestamptz from generate_series(100001, 100000 + $1) n", nil)
-	if err != nil {
-		b.Fatal(err)
-	}
-
-	for _, rowCount := range rowCounts {
-		b.Run(fmt.Sprintf("%d rows", rowCount), func(b *testing.B) {
-			formats := []struct {
-				name string
-				code int16
-			}{
-				{"text", pgx.TextFormatCode},
-				{"binary - mostly", pgx.BinaryFormatCode},
-			}
-			for _, format := range formats {
-				b.Run(format.name, func(b *testing.B) {
-					for i := 0; i < b.N; i++ {
-						rr := conn.PgConn().ExecStatement(
-							context.Background(),
-							psd,
-							[][]byte{[]byte(strconv.FormatInt(rowCount, 10))},
-							nil,
-							[]int16{format.code, pgx.TextFormatCode, pgx.TextFormatCode, pgx.TextFormatCode, format.code, format.code, format.code, format.code, format.code},
-						)
-						for rr.NextRow() {
-							rr.Values()
-						}
-
-						_, err := rr.Close()
-						if err != nil {
-							b.Fatal(err)
-						}
-					}
-				})
-			}
-		})
-	}
-}
-
 type queryRecorder struct {
 	conn      net.Conn
 	writeBuf  []byte
diff --git a/conn.go b/conn.go
index 0823c79a..1fc0b568 100644
--- a/conn.go
+++ b/conn.go
@@ -610,7 +610,7 @@ func (c *Conn) execPrepared(ctx context.Context, sd *pgconn.StatementDescription
 		return pgconn.CommandTag{}, err
 	}
 
-	result := c.pgConn.ExecStatement(ctx, sd, c.eqb.ParamValues, c.eqb.ParamFormats, c.eqb.ResultFormats).Read()
+	result := c.pgConn.ExecPrepared(ctx, sd.Name, c.eqb.ParamValues, c.eqb.ParamFormats, c.eqb.ResultFormats).Read()
 	c.eqb.reset() // Allow c.eqb internal memory to be GC'ed as soon as possible.
 	return result.CommandTag, result.Err
 }
@@ -844,7 +844,7 @@ optionLoop:
 		if !explicitPreparedStatement && mode == QueryExecModeCacheDescribe {
 			rows.resultReader = c.pgConn.ExecParams(ctx, sql, c.eqb.ParamValues, sd.ParamOIDs, c.eqb.ParamFormats, resultFormats)
 		} else {
-			rows.resultReader = c.pgConn.ExecStatement(ctx, sd, c.eqb.ParamValues, c.eqb.ParamFormats, resultFormats)
+			rows.resultReader = c.pgConn.ExecPrepared(ctx, sd.Name, c.eqb.ParamValues, c.eqb.ParamFormats, resultFormats)
 		}
 	} else if mode == QueryExecModeExec {
 		err := c.eqb.Build(c.typeMap, nil, args)
@@ -1236,7 +1236,7 @@ func (c *Conn) sendBatchExtendedWithDescription(ctx context.Context, b *Batch, d
 		if bi.sd.Name == "" {
 			pipeline.SendQueryParams(bi.sd.SQL, c.eqb.ParamValues, bi.sd.ParamOIDs, c.eqb.ParamFormats, c.eqb.ResultFormats)
 		} else {
-			pipeline.SendQueryStatement(bi.sd, c.eqb.ParamValues, c.eqb.ParamFormats, c.eqb.ResultFormats)
+			pipeline.SendQueryPrepared(bi.sd.Name, c.eqb.ParamValues, c.eqb.ParamFormats, c.eqb.ResultFormats)
 		}
 	}
 
diff --git a/pgconn/pgconn.go b/pgconn/pgconn.go
index ec27ec34..a18f1874 100644
--- a/pgconn/pgconn.go
+++ b/pgconn/pgconn.go
@@ -23,7 +23,6 @@ import (
 	"github.com/jackc/pgx/v5/pgconn/ctxwatch"
 	"github.com/jackc/pgx/v5/pgconn/internal/bgreader"
 	"github.com/jackc/pgx/v5/pgproto3"
-	"github.com/jackc/pgx/v5/pgtype"
 )
 
 const (
@@ -829,15 +828,13 @@ type FieldDescription struct {
 	Format               int16
 }
 
-func (pgConn *PgConn) getFieldDescriptionSlice(n int) []FieldDescription {
-	if cap(pgConn.fieldDescriptions) >= n {
-		return pgConn.fieldDescriptions[:n:n]
+func (pgConn *PgConn) convertRowDescription(dst []FieldDescription, rd *pgproto3.RowDescription) []FieldDescription {
+	if cap(dst) >= len(rd.Fields) {
+		dst = dst[:len(rd.Fields):len(rd.Fields)]
 	} else {
-		return make([]FieldDescription, n)
+		dst = make([]FieldDescription, len(rd.Fields))
 	}
-}
 
-func convertRowDescription(dst []FieldDescription, rd *pgproto3.RowDescription) {
 	for i := range rd.Fields {
 		dst[i].Name = string(rd.Fields[i].Name)
 		dst[i].TableOID = rd.Fields[i].TableOID
@@ -847,6 +844,8 @@ func convertRowDescription(dst []FieldDescription, rd *pgproto3.RowDescription)
 		dst[i].TypeModifier = rd.Fields[i].TypeModifier
 		dst[i].Format = rd.Fields[i].Format
 	}
+
+	return dst
 }
 
 type StatementDescription struct {
@@ -910,8 +909,7 @@ readloop:
 			psd.ParamOIDs = make([]uint32, len(msg.ParameterOIDs))
 			copy(psd.ParamOIDs, msg.ParameterOIDs)
 		case *pgproto3.RowDescription:
-			psd.Fields = make([]FieldDescription, len(msg.Fields))
-			convertRowDescription(psd.Fields, msg)
+			psd.Fields = pgConn.convertRowDescription(nil, msg)
 		case *pgproto3.ErrorResponse:
 			pgErr = ErrorResponseToPgError(msg)
 		case *pgproto3.ReadyForQuery:
@@ -1161,7 +1159,7 @@ func (pgConn *PgConn) ExecParams(ctx context.Context, sql string, paramValues []
 	pgConn.frontend.SendParse(&pgproto3.Parse{Query: sql, ParameterOIDs: paramOIDs})
 	pgConn.frontend.SendBind(&pgproto3.Bind{ParameterFormatCodes: paramFormats, Parameters: paramValues, ResultFormatCodes: resultFormats})
 
-	pgConn.execExtendedSuffix(result, nil, nil)
+	pgConn.execExtendedSuffix(result)
 
 	return result
 }
@@ -1186,36 +1184,7 @@ func (pgConn *PgConn) ExecPrepared(ctx context.Context, stmtName string, paramVa
 
 	pgConn.frontend.SendBind(&pgproto3.Bind{PreparedStatement: stmtName, ParameterFormatCodes: paramFormats, Parameters: paramValues, ResultFormatCodes: resultFormats})
 
-	pgConn.execExtendedSuffix(result, nil, nil)
-
-	return result
-}
-
-// ExecStatement enqueues the execution of a prepared statement via the PostgreSQL extended query protocol.
-//
-// This differs from ExecPrepared in that it takes a *StatementDescription instead of the prepared statement name.
-// Because it has the *StatementDescription it can avoid the Describe Portal message that ExecPrepared must send to get
-// the result column descriptions.
-//
-// paramValues are the parameter values. It must be encoded in the format given by paramFormats.
-//
-// paramFormats is a slice of format codes determining for each paramValue column whether it is encoded in text or
-// binary format. If paramFormats is nil all params are text format. ExecPrepared will panic if len(paramFormats) is not
-// 0, 1, or len(paramValues).
-//
-// resultFormats is a slice of format codes determining for each result column whether it is encoded in text or binary
-// format. If resultFormats is nil all results will be in text format.
-//
-// ResultReader must be closed before PgConn can be used again.
-func (pgConn *PgConn) ExecStatement(ctx context.Context, statementDescription *StatementDescription, paramValues [][]byte, paramFormats, resultFormats []int16) *ResultReader {
-	result := pgConn.execExtendedPrefix(ctx, paramValues)
-	if result.closed {
-		return result
-	}
-
-	pgConn.frontend.SendBind(&pgproto3.Bind{PreparedStatement: statementDescription.Name, ParameterFormatCodes: paramFormats, Parameters: paramValues, ResultFormatCodes: resultFormats})
-
-	pgConn.execExtendedSuffix(result, statementDescription, resultFormats)
+	pgConn.execExtendedSuffix(result)
 
 	return result
 }
@@ -1255,10 +1224,8 @@ func (pgConn *PgConn) execExtendedPrefix(ctx context.Context, paramValues [][]by
 	return result
 }
 
-func (pgConn *PgConn) execExtendedSuffix(result *ResultReader, statementDescription *StatementDescription, resultFormats []int16) {
-	if statementDescription == nil {
-		pgConn.frontend.SendDescribe(&pgproto3.Describe{ObjectType: 'P'})
-	}
+func (pgConn *PgConn) execExtendedSuffix(result *ResultReader) {
+	pgConn.frontend.SendDescribe(&pgproto3.Describe{ObjectType: 'P'})
 	pgConn.frontend.SendExecute(&pgproto3.Execute{})
 	pgConn.frontend.SendSync(&pgproto3.Sync{})
 
@@ -1272,7 +1239,7 @@ func (pgConn *PgConn) execExtendedSuffix(result *ResultReader, statementDescript
 		return
 	}
 
-	result.readUntilRowDescription(statementDescription, resultFormats)
+	result.readUntilRowDescription()
 }
 
 // CopyTo executes the copy command sql and copies the results to w.
@@ -1475,10 +1442,6 @@ type MultiResultReader struct {
 
 	rr *ResultReader
 
-	// Data from when the batch was queued.
-	statementDescriptions []*StatementDescription
-	resultFormats         [][]int16
-
 	closed bool
 	err    error
 }
@@ -1520,39 +1483,6 @@ func (mrr *MultiResultReader) receiveMessage() (pgproto3.BackendMessage, error)
 // NextResult returns advances the MultiResultReader to the next result and returns true if a result is available.
 func (mrr *MultiResultReader) NextResult() bool {
 	for !mrr.closed && mrr.err == nil {
-		msg, _ := mrr.pgConn.peekMessage()
-		if _, ok := msg.(*pgproto3.DataRow); ok {
-			if len(mrr.statementDescriptions) > 0 {
-				rr := ResultReader{
-					pgConn:            mrr.pgConn,
-					multiResultReader: mrr,
-					ctx:               mrr.ctx,
-				}
-
-				// This result corresponds to a prepared statement description that was provided when queuing the batch.
-				sd := mrr.statementDescriptions[0]
-				mrr.statementDescriptions = mrr.statementDescriptions[1:]
-
-				resultFormats := mrr.resultFormats[0]
-				mrr.resultFormats = mrr.resultFormats[1:]
-
-				sdFields := sd.Fields
-				rr.fieldDescriptions = rr.pgConn.getFieldDescriptionSlice(len(sdFields))
-
-				err := combineFieldDescriptionsAndResultFormats(rr.fieldDescriptions, sdFields, resultFormats)
-				if err != nil {
-					rr.concludeCommand(CommandTag{}, err)
-				}
-
-				mrr.pgConn.resultReader = rr
-				mrr.rr = &mrr.pgConn.resultReader
-				return true
-			}
-
-			mrr.err = fmt.Errorf("unexpected DataRow message without preceding RowDescription")
-			return false
-		}
-
 		msg, err := mrr.receiveMessage()
 		if err != nil {
 			return false
@@ -1564,9 +1494,8 @@ func (mrr *MultiResultReader) NextResult() bool {
 				pgConn:            mrr.pgConn,
 				multiResultReader: mrr,
 				ctx:               mrr.ctx,
-				fieldDescriptions: mrr.pgConn.getFieldDescriptionSlice(len(msg.Fields)),
+				fieldDescriptions: mrr.pgConn.convertRowDescription(mrr.pgConn.fieldDescriptions[:], msg),
 			}
-			convertRowDescription(mrr.pgConn.resultReader.fieldDescriptions, msg)
 
 			mrr.rr = &mrr.pgConn.resultReader
 			return true
@@ -1618,7 +1547,6 @@ type ResultReader struct {
 	fieldDescriptions []FieldDescription
 	rowValues         [][]byte
 	commandTag        CommandTag
-	preloaded         bool
 	commandConcluded  bool
 	closed            bool
 	err               error
@@ -1660,11 +1588,6 @@ func (rr *ResultReader) Read() *Result {
 
 // NextRow advances the ResultReader to the next row and returns true if a row is available.
 func (rr *ResultReader) NextRow() bool {
-	if rr.preloaded {
-		rr.preloaded = false
-		return true
-	}
-
 	for !rr.commandConcluded {
 		msg, err := rr.receiveMessage()
 		if err != nil {
@@ -1681,11 +1604,6 @@ func (rr *ResultReader) NextRow() bool {
 	return false
 }
 
-func (rr *ResultReader) preloadRowValues(values [][]byte) {
-	rr.rowValues = values
-	rr.preloaded = true
-}
-
 // FieldDescriptions returns the field descriptions for the current result set. The returned slice is only valid until
 // the ResultReader is closed. It may return nil (for example, if the query did not return a result set or an error was
 // encountered.)
@@ -1738,34 +1656,19 @@ func (rr *ResultReader) Close() (CommandTag, error) {
 
 // readUntilRowDescription ensures the ResultReader's fieldDescriptions are loaded. It does not return an error as any
 // error will be stored in the ResultReader.
-func (rr *ResultReader) readUntilRowDescription(statementDescription *StatementDescription, resultFormats []int16) {
+func (rr *ResultReader) readUntilRowDescription() {
 	for !rr.commandConcluded {
-		msg, _ := rr.receiveMessage()
-		switch msg := msg.(type) {
-		case *pgproto3.RowDescription:
-			return
-		case *pgproto3.DataRow:
-			rr.preloadRowValues(msg.Values)
-			if statementDescription != nil {
-				sdFields := statementDescription.Fields
-				rr.fieldDescriptions = rr.pgConn.getFieldDescriptionSlice(len(sdFields))
-
-				err := combineFieldDescriptionsAndResultFormats(rr.fieldDescriptions, sdFields, resultFormats)
-				if err != nil {
-					rr.concludeCommand(CommandTag{}, err)
-				}
-			}
+		// Peek before receive to avoid consuming a DataRow if the result set does not include a RowDescription method.
+		// This should never happen under normal pgconn usage, but it is possible if SendBytes and ReceiveResults are
+		// manually used to construct a query that does not issue a describe statement.
+		msg, _ := rr.pgConn.peekMessage()
+		if _, ok := msg.(*pgproto3.DataRow); ok {
 			return
-		case *pgproto3.CommandComplete:
-			if statementDescription != nil {
-				sdFields := statementDescription.Fields
-				rr.fieldDescriptions = rr.pgConn.getFieldDescriptionSlice(len(sdFields))
+		}
 
-				err := combineFieldDescriptionsAndResultFormats(rr.fieldDescriptions, sdFields, resultFormats)
-				if err != nil {
-					rr.concludeCommand(CommandTag{}, err)
-				}
-			}
+		// Consume the message
+		msg, _ = rr.receiveMessage()
+		if _, ok := msg.(*pgproto3.RowDescription); ok {
 			return
 		}
 	}
@@ -1792,8 +1695,7 @@ func (rr *ResultReader) receiveMessage() (msg pgproto3.BackendMessage, err error
 
 	switch msg := msg.(type) {
 	case *pgproto3.RowDescription:
-		rr.fieldDescriptions = rr.pgConn.getFieldDescriptionSlice(len(msg.Fields))
-		convertRowDescription(rr.fieldDescriptions, msg)
+		rr.fieldDescriptions = rr.pgConn.convertRowDescription(rr.pgConn.fieldDescriptions[:], msg)
 	case *pgproto3.CommandComplete:
 		rr.concludeCommand(rr.pgConn.makeCommandTag(msg.CommandTag), nil)
 	case *pgproto3.EmptyQueryResponse:
@@ -1827,10 +1729,8 @@ func (rr *ResultReader) concludeCommand(commandTag CommandTag, err error) {
 
 // Batch is a collection of queries that can be sent to the PostgreSQL server in a single round-trip.
 type Batch struct {
-	buf                   []byte
-	statementDescriptions []*StatementDescription
-	resultFormats         [][]int16
-	err                   error
+	buf []byte
+	err error
 }
 
 // ExecParams appends an ExecParams command to the batch. See PgConn.ExecParams for parameter descriptions.
@@ -1868,30 +1768,6 @@ func (batch *Batch) ExecPrepared(stmtName string, paramValues [][]byte, paramFor
 	}
 }
 
-// ExecStatement appends an ExecStatement command to the batch. See PgConn.ExecPrepared for parameter descriptions.
-//
-// This differs from ExecPrepared in that it takes a *StatementDescription instead of just the prepared statement name.
-// Because it has the *StatementDescription it can avoid the Describe Portal message that ExecPrepared must send to get
-// the result column descriptions.
-func (batch *Batch) ExecStatement(statementDescription *StatementDescription, paramValues [][]byte, paramFormats, resultFormats []int16) {
-	if batch.err != nil {
-		return
-	}
-
-	batch.buf, batch.err = (&pgproto3.Bind{PreparedStatement: statementDescription.Name, ParameterFormatCodes: paramFormats, Parameters: paramValues, ResultFormatCodes: resultFormats}).Encode(batch.buf)
-	if batch.err != nil {
-		return
-	}
-
-	batch.statementDescriptions = append(batch.statementDescriptions, statementDescription)
-	batch.resultFormats = append(batch.resultFormats, resultFormats)
-
-	batch.buf, batch.err = (&pgproto3.Execute{}).Encode(batch.buf)
-	if batch.err != nil {
-		return
-	}
-}
-
 // ExecBatch executes all the queries in batch in a single round-trip. Execution is implicitly transactional unless a
 // transaction is already in progress or SQL contains transaction control statements. This is a simpler way of executing
 // multiple queries in a single round trip than using pipeline mode.
@@ -1911,10 +1787,8 @@ func (pgConn *PgConn) ExecBatch(ctx context.Context, batch *Batch) *MultiResultR
 	}
 
 	pgConn.multiResultReader = MultiResultReader{
-		pgConn:                pgConn,
-		ctx:                   ctx,
-		statementDescriptions: batch.statementDescriptions,
-		resultFormats:         batch.resultFormats,
+		pgConn: pgConn,
+		ctx:    ctx,
 	}
 	multiResult := &pgConn.multiResultReader
 
@@ -2149,10 +2023,9 @@ func Construct(hc *HijackedConn) (*PgConn, error) {
 
 // Pipeline represents a connection in pipeline mode.
 //
-// SendPrepare, SendQueryParams, SendQueryPrepared, and SendQueryStatement queue requests to the server. These requests
-// are not written until pipeline is flushed by Flush or Sync. Sync must be called after the last request is queued.
-// Requests between synchronization points are implicitly transactional unless explicit transaction control statements
-// have been issued.
+// SendPrepare, SendQueryParams, and SendQueryPrepared queue requests to the server. These requests are not written until
+// pipeline is flushed by Flush or Sync. Sync must be called after the last request is queued. Requests between
+// synchronization points are implicitly transactional unless explicit transaction control statements have been issued.
 //
 // The context the pipeline was started with is in effect for the entire life of the Pipeline.
 //
@@ -2181,7 +2054,6 @@ const (
 	pipelinePrepare
 	pipelineQueryParams
 	pipelineQueryPrepared
-	pipelineQueryStatement
 	pipelineDeallocate
 	pipelineSyncRequest
 	pipelineFlushRequest
@@ -2195,8 +2067,6 @@ type pipelineRequestEvent struct {
 
 type pipelineState struct {
 	requestEventQueue          list.List
-	statementDescriptionsQueue list.List
-	resultFormatsQueue         list.List
 	lastRequestType            pipelineRequestType
 	pgErr                      *PgError
 	expectedReadyForQueryCount int
@@ -2204,8 +2074,6 @@ type pipelineState struct {
 
 func (s *pipelineState) Init() {
 	s.requestEventQueue.Init()
-	s.statementDescriptionsQueue.Init()
-	s.resultFormatsQueue.Init()
 	s.lastRequestType = pipelineNil
 }
 
@@ -2270,29 +2138,6 @@ func (s *pipelineState) ExtractFrontRequestType() pipelineRequestType {
 	}
 }
 
-func (s *pipelineState) PushBackStatementData(sd *StatementDescription, resultFormats []int16) {
-	s.statementDescriptionsQueue.PushBack(sd)
-	s.resultFormatsQueue.PushBack(resultFormats)
-}
-
-func (s *pipelineState) ExtractFrontStatementData() (*StatementDescription, []int16) {
-	sdElem := s.statementDescriptionsQueue.Front()
-	var sd *StatementDescription
-	if sdElem != nil {
-		s.statementDescriptionsQueue.Remove(sdElem)
-		sd = sdElem.Value.(*StatementDescription)
-	}
-
-	rfElem := s.resultFormatsQueue.Front()
-	var resultFormats []int16
-	if rfElem != nil {
-		s.resultFormatsQueue.Remove(rfElem)
-		resultFormats = rfElem.Value.([]int16)
-	}
-
-	return sd, resultFormats
-}
-
 func (s *pipelineState) HandleError(err *PgError) {
 	s.pgErr = err
 }
@@ -2335,8 +2180,6 @@ func (pgConn *PgConn) StartPipeline(ctx context.Context) *Pipeline {
 		return pipeline
 	}
 
-	pgConn.resultReader = ResultReader{closed: true}
-
 	pgConn.pipeline = Pipeline{
 		conn: pgConn,
 		ctx:  ctx,
@@ -2406,18 +2249,6 @@ func (p *Pipeline) SendQueryPrepared(stmtName string, paramValues [][]byte, para
 	p.state.PushBackRequestType(pipelineQueryPrepared)
 }
 
-// SendQueryStatement is the pipeline version of *PgConn.ExecStatement.
-func (p *Pipeline) SendQueryStatement(statementDescription *StatementDescription, paramValues [][]byte, paramFormats, resultFormats []int16) {
-	if p.closed {
-		return
-	}
-
-	p.conn.frontend.SendBind(&pgproto3.Bind{PreparedStatement: statementDescription.Name, ParameterFormatCodes: paramFormats, Parameters: paramValues, ResultFormatCodes: resultFormats})
-	p.conn.frontend.SendExecute(&pgproto3.Execute{})
-	p.state.PushBackRequestType(pipelineQueryStatement)
-	p.state.PushBackStatementData(statementDescription, resultFormats)
-}
-
 // SendFlushRequest sends a request for the server to flush its output buffer.
 //
 // The server flushes its output buffer automatically as a result of Sync being called,
@@ -2492,317 +2323,99 @@ func (p *Pipeline) GetResults() (results any, err error) {
 		return nil, errors.New("pipeline closed")
 	}
 
+	if p.state.ExtractFrontRequestType() == pipelineNil {
+		return nil, nil
+	}
+
 	return p.getResults()
 }
 
 func (p *Pipeline) getResults() (results any, err error) {
-	if !p.conn.resultReader.closed {
-		_, err := p.conn.resultReader.Close()
+	for {
+		msg, err := p.conn.receiveMessage()
 		if err != nil {
-			return nil, err
+			p.closed = true
+			p.err = err
+			p.conn.asyncClose()
+			return nil, normalizeTimeoutError(p.ctx, err)
 		}
-	}
 
-	currentRequestType := p.state.ExtractFrontRequestType()
-	switch currentRequestType {
-	case pipelineNil:
-		return nil, nil
-	case pipelinePrepare:
-		return p.getResultsPrepare()
-	case pipelineQueryParams:
-		return p.getResultsQueryParams()
-	case pipelineQueryPrepared:
-		return p.getResultsQueryPrepared()
-	case pipelineQueryStatement:
-		return p.getResultsQueryStatement()
-	case pipelineDeallocate:
-		return p.getResultsDeallocate()
-	case pipelineSyncRequest:
-		return p.getResultsSync()
-	case pipelineFlushRequest:
-		return nil, errors.New("BUG: pipelineFlushRequest should not be in request queue")
-	default:
-		return nil, errors.New("BUG: unknown pipeline request type")
+		switch msg := msg.(type) {
+		case *pgproto3.RowDescription:
+			p.conn.resultReader = ResultReader{
+				pgConn:            p.conn,
+				pipeline:          p,
+				ctx:               p.ctx,
+				fieldDescriptions: p.conn.convertRowDescription(p.conn.fieldDescriptions[:], msg),
+			}
+			return &p.conn.resultReader, nil
+		case *pgproto3.CommandComplete:
+			p.conn.resultReader = ResultReader{
+				commandTag:       p.conn.makeCommandTag(msg.CommandTag),
+				commandConcluded: true,
+				closed:           true,
+			}
+			return &p.conn.resultReader, nil
+		case *pgproto3.ParseComplete:
+			peekedMsg, err := p.conn.peekMessage()
+			if err != nil {
+				p.conn.asyncClose()
+				return nil, normalizeTimeoutError(p.ctx, err)
+			}
+			if _, ok := peekedMsg.(*pgproto3.ParameterDescription); ok {
+				return p.getResultsPrepare()
+			}
+		case *pgproto3.CloseComplete:
+			return &CloseComplete{}, nil
+		case *pgproto3.ReadyForQuery:
+			p.state.HandleReadyForQuery()
+			return &PipelineSync{}, nil
+		case *pgproto3.ErrorResponse:
+			pgErr := ErrorResponseToPgError(msg)
+			p.state.HandleError(pgErr)
+			return nil, pgErr
+		}
 	}
 }
 
 func (p *Pipeline) getResultsPrepare() (*StatementDescription, error) {
-	err := p.receiveParseComplete("Prepare")
-	if err != nil {
-		return nil, err
-	}
-
 	psd := &StatementDescription{}
 
-	msg, err := p.receiveMessage()
-	if err != nil {
-		return nil, err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.ParameterDescription:
-		psd.ParamOIDs = make([]uint32, len(msg.ParameterOIDs))
-		copy(psd.ParamOIDs, msg.ParameterOIDs)
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		return nil, pgErr
-	default:
-		return nil, p.handleUnexpectedMessage("Prepare ParameterDescription", msg)
-	}
-
-	msg, err = p.receiveMessage()
-	if err != nil {
-		return nil, err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.RowDescription:
-		psd.Fields = make([]FieldDescription, len(msg.Fields))
-		convertRowDescription(psd.Fields, msg)
-		return psd, nil
-
-	// NoData is returned instead of RowDescription when there is no expected result. e.g. An INSERT without a RETURNING
-	// clause.
-	case *pgproto3.NoData:
-		return psd, nil
-
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		return nil, pgErr
-	default:
-		return nil, p.handleUnexpectedMessage("Prepare RowDescription", msg)
-	}
-}
-
-func (p *Pipeline) getResultsQueryParams() (*ResultReader, error) {
-	err := p.receiveParseComplete("QueryParams")
-	if err != nil {
-		return nil, err
-	}
-
-	err = p.receiveBindComplete("QueryParams")
-	if err != nil {
-		return nil, err
-	}
-
-	return p.receiveDescribedResultReader("QueryParams")
-}
-
-func (p *Pipeline) getResultsQueryPrepared() (*ResultReader, error) {
-	err := p.receiveBindComplete("QueryPrepared")
-	if err != nil {
-		return nil, err
-	}
-
-	return p.receiveDescribedResultReader("QueryPrepared")
-}
-
-func (p *Pipeline) getResultsQueryStatement() (*ResultReader, error) {
-	err := p.receiveBindComplete("QueryStatement")
-	if err != nil {
-		return nil, err
-	}
-
-	msg, err := p.receiveMessage()
-	if err != nil {
-		return nil, err
-	}
-
-	sd, resultFormats := p.state.ExtractFrontStatementData()
-	if sd == nil {
-		return nil, errors.New("BUG: missing statement description or result formats for QueryStatement")
-	}
-	sdFields := sd.Fields
-	fieldDescriptions := p.conn.getFieldDescriptionSlice(len(sdFields))
-	err = combineFieldDescriptionsAndResultFormats(fieldDescriptions, sdFields, resultFormats)
-	if err != nil {
-		return nil, err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.DataRow:
-		rr := ResultReader{
-			pgConn:            p.conn,
-			pipeline:          p,
-			ctx:               p.ctx,
-			fieldDescriptions: fieldDescriptions,
-		}
-		rr.preloadRowValues(msg.Values)
-		p.conn.resultReader = rr
-		return &p.conn.resultReader, nil
-	case *pgproto3.CommandComplete:
-		p.conn.resultReader = ResultReader{
-			commandTag:        p.conn.makeCommandTag(msg.CommandTag),
-			commandConcluded:  true,
-			closed:            true,
-			fieldDescriptions: fieldDescriptions,
-		}
-		return &p.conn.resultReader, nil
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		p.conn.resultReader.closed = true
-		return nil, pgErr
-	default:
-		return nil, p.handleUnexpectedMessage("QueryStatement", msg)
-	}
-}
-
-func (p *Pipeline) getResultsDeallocate() (*CloseComplete, error) {
-	msg, err := p.receiveMessage()
-	if err != nil {
-		return nil, err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.CloseComplete:
-		return &CloseComplete{}, nil
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		p.conn.resultReader.closed = true
-		return nil, pgErr
-	default:
-		return nil, p.handleUnexpectedMessage("Deallocate", msg)
-	}
-}
-
-func (p *Pipeline) getResultsSync() (*PipelineSync, error) {
-	msg, err := p.receiveMessage()
-	if err != nil {
-		return nil, err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.ReadyForQuery:
-		p.state.HandleReadyForQuery()
-		return &PipelineSync{}, nil
-	case *pgproto3.ErrorResponse:
-		// Error message that is received while expecting a Sync message still consumes the expected Sync. Put it back.
-		p.state.requestEventQueue.PushFront(pipelineRequestEvent{RequestType: pipelineSyncRequest, WasSentToServer: true, BeforeFlushOrSync: true})
-
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		p.conn.resultReader.closed = true
-		return nil, pgErr
-	default:
-		return nil, p.handleUnexpectedMessage("Sync", msg)
-	}
-}
-
-func (p *Pipeline) receiveParseComplete(errStr string) error {
-	msg, err := p.receiveMessage()
-	if err != nil {
-		return err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.ParseComplete:
-		return nil
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		return pgErr
-	default:
-		return p.handleUnexpectedMessage(fmt.Sprintf("%s Parse", errStr), msg)
-	}
-}
-
-func (p *Pipeline) receiveBindComplete(errStr string) error {
-	msg, err := p.receiveMessage()
-	if err != nil {
-		return err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.BindComplete:
-		return nil
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		return pgErr
-	default:
-		return p.handleUnexpectedMessage(fmt.Sprintf("%s Bind", errStr), msg)
-	}
-}
-
-func (p *Pipeline) receiveDescribedResultReader(errStr string) (*ResultReader, error) {
-	msg, err := p.receiveMessage()
-	if err != nil {
-		return nil, err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.RowDescription:
-		p.conn.resultReader = ResultReader{
-			pgConn:            p.conn,
-			pipeline:          p,
-			ctx:               p.ctx,
-			fieldDescriptions: p.conn.getFieldDescriptionSlice(len(msg.Fields)),
-		}
-		convertRowDescription(p.conn.resultReader.fieldDescriptions, msg)
-		return &p.conn.resultReader, nil
-	case *pgproto3.NoData:
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		p.conn.resultReader.closed = true
-		return nil, pgErr
-	default:
-		return nil, p.handleUnexpectedMessage(fmt.Sprintf("%s RowDescription or NoData", errStr), msg)
-	}
-
-	msg, err = p.receiveMessage()
-	if err != nil {
-		return nil, err
-	}
-
-	switch msg := msg.(type) {
-	case *pgproto3.CommandComplete:
-		p.conn.resultReader = ResultReader{
-			commandTag:       p.conn.makeCommandTag(msg.CommandTag),
-			commandConcluded: true,
-			closed:           true,
-		}
-		return &p.conn.resultReader, nil
-	case *pgproto3.ErrorResponse:
-		pgErr := ErrorResponseToPgError(msg)
-		p.state.HandleError(pgErr)
-		p.conn.resultReader.closed = true
-		return nil, pgErr
-	default:
-		return nil, p.handleUnexpectedMessage(fmt.Sprintf("%s CommandComplete", errStr), msg)
-	}
-}
-
-func (p *Pipeline) receiveMessage() (pgproto3.BackendMessage, error) {
 	for {
 		msg, err := p.conn.receiveMessage()
 		if err != nil {
-			p.closed = true
-			p.err = err
 			p.conn.asyncClose()
 			return nil, normalizeTimeoutError(p.ctx, err)
 		}
 
 		switch msg := msg.(type) {
-		case *pgproto3.ParameterStatus, *pgproto3.NoticeResponse, *pgproto3.NotificationResponse:
-			// Filter these message types out in pipeline mode. The normal processing is handled by PgConn.receiveMessage.
-		default:
-			return msg, nil
+		case *pgproto3.ParameterDescription:
+			psd.ParamOIDs = make([]uint32, len(msg.ParameterOIDs))
+			copy(psd.ParamOIDs, msg.ParameterOIDs)
+		case *pgproto3.RowDescription:
+			psd.Fields = p.conn.convertRowDescription(nil, msg)
+			return psd, nil
+
+		// NoData is returned instead of RowDescription when there is no expected result. e.g. An INSERT without a RETURNING
+		// clause.
+		case *pgproto3.NoData:
+			return psd, nil
+
+		// These should never happen here. But don't take chances that could lead to a deadlock.
+		case *pgproto3.ErrorResponse:
+			pgErr := ErrorResponseToPgError(msg)
+			p.state.HandleError(pgErr)
+			return nil, pgErr
+		case *pgproto3.CommandComplete:
+			p.conn.asyncClose()
+			return nil, errors.New("BUG: received CommandComplete while handling Describe")
+		case *pgproto3.ReadyForQuery:
+			p.conn.asyncClose()
+			return nil, errors.New("BUG: received ReadyForQuery while handling Describe")
 		}
 	}
 }
 
-func (p *Pipeline) handleUnexpectedMessage(errStr string, msg pgproto3.BackendMessage) error {
-	p.closed = true
-	p.err = fmt.Errorf("pipeline: %s: received unexpected message type %T", errStr, msg)
-	p.conn.asyncClose()
-	return p.err
-}
-
 // Close closes the pipeline and returns the connection to normal mode.
 func (p *Pipeline) Close() error {
 	if p.closed {
@@ -2905,32 +2518,3 @@ func (h *CancelRequestContextWatcherHandler) HandleUnwatchAfterCancel() {
 
 	h.Conn.conn.SetDeadline(time.Time{})
 }
-
-func combineFieldDescriptionsAndResultFormats(outputFields, inputFields []FieldDescription, resultFormats []int16) error {
-	switch {
-	case len(resultFormats) == 0:
-		// No format codes provided means text format for all columns.
-		for i := range inputFields {
-			outputFields[i] = inputFields[i]
-			outputFields[i].Format = pgtype.TextFormatCode
-		}
-	case len(resultFormats) == 1:
-		// Single format code applies to all columns.
-		format := resultFormats[0]
-		for i := range inputFields {
-			outputFields[i] = inputFields[i]
-			outputFields[i].Format = format
-		}
-	case len(resultFormats) == len(inputFields):
-		// One format code per column.
-		for i := range inputFields {
-			outputFields[i] = inputFields[i]
-			outputFields[i].Format = resultFormats[i]
-		}
-	default:
-		// This should not occur if Bind validation is correct, but handle gracefully
-		return fmt.Errorf("result format codes length %d does not match field count %d", len(resultFormats), len(inputFields))
-	}
-
-	return nil
-}
diff --git a/pgconn/pgconn_test.go b/pgconn/pgconn_test.go
index 3fd43a03..001b6345 100644
--- a/pgconn/pgconn_test.go
+++ b/pgconn/pgconn_test.go
@@ -1435,146 +1435,6 @@ func TestConnExecPreparedEmptySQL(t *testing.T) {
 	ensureConnValid(t, pgConn)
 }
 
-func TestConnExecStatement(t *testing.T) {
-	t.Parallel()
-
-	ctx, cancel := context.WithTimeout(context.Background(), 120*time.Second)
-	defer cancel()
-
-	pgConn, err := pgconn.Connect(ctx, os.Getenv("PGX_TEST_DATABASE"))
-	require.NoError(t, err)
-	defer closeConn(t, pgConn)
-
-	psd, err := pgConn.Prepare(ctx, "ps1", "select $1::text as msg", nil)
-	require.NoError(t, err)
-	require.NotNil(t, psd)
-	assert.Len(t, psd.ParamOIDs, 1)
-	assert.Len(t, psd.Fields, 1)
-
-	result := pgConn.ExecStatement(ctx, psd, [][]byte{[]byte("Hello, world")}, nil, nil)
-	require.Len(t, result.FieldDescriptions(), 1)
-	assert.Equal(t, "msg", result.FieldDescriptions()[0].Name)
-
-	rowCount := 0
-	for result.NextRow() {
-		rowCount += 1
-		assert.Equal(t, "Hello, world", string(result.Values()[0]))
-	}
-	assert.Equal(t, 1, rowCount)
-	commandTag, err := result.Close()
-	assert.Equal(t, "SELECT 1", commandTag.String())
-	assert.NoError(t, err)
-
-	ensureConnValid(t, pgConn)
-}
-
-type byteCounterConn struct {
-	conn         net.Conn
-	bytesRead    int
-	bytesWritten int
-}
-
-func (cbn *byteCounterConn) Read(b []byte) (n int, err error) {
-	n, err = cbn.conn.Read(b)
-	cbn.bytesRead += n
-	return n, err
-}
-
-func (cbn *byteCounterConn) Write(b []byte) (n int, err error) {
-	n, err = cbn.conn.Write(b)
-	cbn.bytesWritten += n
-	return n, err
-}
-
-func (cbn *byteCounterConn) Close() error {
-	return cbn.conn.Close()
-}
-
-func (cbn *byteCounterConn) LocalAddr() net.Addr {
-	return cbn.conn.LocalAddr()
-}
-
-func (cbn *byteCounterConn) RemoteAddr() net.Addr {
-	return cbn.conn.RemoteAddr()
-}
-
-func (cbn *byteCounterConn) SetDeadline(t time.Time) error {
-	return cbn.conn.SetDeadline(t)
-}
-
-func (cbn *byteCounterConn) SetReadDeadline(t time.Time) error {
-	return cbn.conn.SetReadDeadline(t)
-}
-
-func (cbn *byteCounterConn) SetWriteDeadline(t time.Time) error {
-	return cbn.conn.SetWriteDeadline(t)
-}
-
-func TestConnExecStatementNetworkUsage(t *testing.T) {
-	t.Parallel()
-
-	ctx, cancel := context.WithTimeout(context.Background(), 120*time.Second)
-	defer cancel()
-
-	config, err := pgconn.ParseConfig(os.Getenv("PGX_TEST_DATABASE"))
-	require.NoError(t, err)
-
-	var counterConn *byteCounterConn
-	config.AfterNetConnect = func(ctx context.Context, config *pgconn.Config, conn net.Conn) (net.Conn, error) {
-		counterConn = &byteCounterConn{conn: conn}
-		return counterConn, nil
-	}
-
-	pgConn, err := pgconn.ConnectConfig(ctx, config)
-	require.NoError(t, err)
-	defer closeConn(t, pgConn)
-	require.NotNil(t, counterConn)
-
-	if pgConn.ParameterStatus("crdb_version") != "" {
-		t.Skip("Server uses different number of bytes for same operations")
-	}
-
-	psd, err := pgConn.Prepare(ctx, "ps1", "select n, 'Adam', 'Smith ' || n, 'male', '1952-06-16'::date, 258, 72, '{foo,bar,baz}'::text[], '2001-01-28 01:02:03-05'::timestamptz from generate_series(100001, 100000 + $1) n", nil)
-	require.NoError(t, err)
-	require.NotNil(t, psd)
-	assert.Len(t, psd.ParamOIDs, 1)
-	assert.Len(t, psd.Fields, 9)
-
-	counterConn.bytesWritten = 0
-	counterConn.bytesRead = 0
-
-	result := pgConn.ExecPrepared(ctx,
-		psd.Name,
-		[][]byte{[]byte("1")},
-		nil,
-		[]int16{pgx.BinaryFormatCode, pgx.TextFormatCode, pgx.TextFormatCode, pgx.TextFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode},
-	).Read()
-	require.NoError(t, result.Err)
-	withDescribeBytesWritten := counterConn.bytesWritten
-	withDescribeBytesRead := counterConn.bytesRead
-
-	counterConn.bytesWritten = 0
-	counterConn.bytesRead = 0
-
-	result = pgConn.ExecStatement(
-		ctx,
-		psd,
-		[][]byte{[]byte("1")},
-		nil,
-		[]int16{pgx.BinaryFormatCode, pgx.TextFormatCode, pgx.TextFormatCode, pgx.TextFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode, pgx.BinaryFormatCode},
-	).Read()
-	require.NoError(t, result.Err)
-	noDescribeBytesWritten := counterConn.bytesWritten
-	noDescribeBytesRead := counterConn.bytesRead
-
-	assert.Equal(t, 61, withDescribeBytesWritten)
-	assert.Equal(t, 54, noDescribeBytesWritten)
-	assert.Equal(t, 391, withDescribeBytesRead)
-	assert.Equal(t, 153, noDescribeBytesRead)
-
-	ensureConnValid(t, pgConn)
-}
-
 func TestConnExecBatch(t *testing.T) {
 	t.Parallel()
 
@@ -1588,20 +1448,14 @@ func TestConnExecBatch(t *testing.T) {
 	_, err = pgConn.Prepare(ctx, "ps1", "select $1::text", nil)
 	require.NoError(t, err)
 
-	sd, err := pgConn.Prepare(ctx, "ps2", "select $1::text as name, $2::bigint as age", nil)
-	require.NoError(t, err)
-
 	batch := &pgconn.Batch{}
 
 	batch.ExecParams("select $1::text", [][]byte{[]byte("ExecParams 1")}, nil, nil, nil)
 	batch.ExecPrepared("ps1", [][]byte{[]byte("ExecPrepared 1")}, nil, nil)
-	batch.ExecStatement(sd, [][]byte{[]byte("ExecStatement 1"), []byte("42")}, nil, nil)
-	batch.ExecStatement(sd, [][]byte{[]byte("ExecStatement 2"), []byte("43")}, nil, []int16{pgx.BinaryFormatCode})
-	batch.ExecStatement(sd, [][]byte{[]byte("ExecStatement 3"), []byte("44")}, nil, []int16{pgx.TextFormatCode, pgx.BinaryFormatCode})
 	batch.ExecParams("select $1::text", [][]byte{[]byte("ExecParams 2")}, nil, nil, nil)
 	results, err := pgConn.ExecBatch(ctx, batch).ReadAll()
 	require.NoError(t, err)
-	require.Len(t, results, 6)
+	require.Len(t, results, 3)
 
 	require.Len(t, results[0].Rows, 1)
 	require.Equal(t, "ExecParams 1", string(results[0].Rows[0][0]))
@@ -1612,22 +1466,7 @@ func TestConnExecBatch(t *testing.T) {
 	assert.Equal(t, "SELECT 1", results[1].CommandTag.String())
 
 	require.Len(t, results[2].Rows, 1)
-	require.Equal(t, "ExecStatement 1", string(results[2].Rows[0][0]))
-	require.Equal(t, "42", string(results[2].Rows[0][1]))
-	assert.Equal(t, "SELECT 1", results[2].CommandTag.String())
-
-	require.Len(t, results[3].Rows, 1)
-	require.Equal(t, "ExecStatement 2", string(results[3].Rows[0][0]))
-	require.Equal(t, []byte{0, 0, 0, 0, 0, 0, 0, 43}, results[3].Rows[0][1])
-	assert.Equal(t, "SELECT 1", results[3].CommandTag.String())
-
-	require.Len(t, results[4].Rows, 1)
-	require.Equal(t, "ExecStatement 3", string(results[4].Rows[0][0]))
-	require.Equal(t, []byte{0, 0, 0, 0, 0, 0, 0, 44}, results[4].Rows[0][1])
-	assert.Equal(t, "SELECT 1", results[4].CommandTag.String())
-
-	require.Len(t, results[5].Rows, 1)
-	require.Equal(t, "ExecParams 2", string(results[5].Rows[0][0]))
+	require.Equal(t, "ExecParams 2", string(results[2].Rows[0][0]))
 	assert.Equal(t, "SELECT 1", results[2].CommandTag.String())
 }
 
@@ -3760,47 +3599,6 @@ func TestPipelineFlushWithError(t *testing.T) {
 	ensureConnValid(t, pgConn)
 }
 
-func TestPipelineGetResultsHandlesPartiallyReadResults(t *testing.T) {
-	t.Parallel()
-
-	ctx, cancel := context.WithTimeout(context.Background(), 120*time.Second)
-	defer cancel()
-
-	pgConn, err := pgconn.Connect(ctx, os.Getenv("PGX_TEST_DATABASE"))
-	require.NoError(t, err)
-	defer closeConn(t, pgConn)
-
-	sd, err := pgConn.Prepare(ctx, "ps", "select n from generate_series($1::int, $2::int) n", nil)
-	require.NoError(t, err)
-
-	pipeline := pgConn.StartPipeline(ctx)
-	pipeline.SendQueryStatement(sd, [][]byte{[]byte("1"), []byte("3")}, nil, nil)
-	pipeline.SendQueryStatement(sd, [][]byte{[]byte("5"), []byte("7")}, nil, nil)
-	err = pipeline.Sync()
-	require.NoError(t, err)
-
-	results, err := pipeline.GetResults()
-	require.NoError(t, err)
-	rr, ok := results.(*pgconn.ResultReader)
-	require.Truef(t, ok, "expected ResultReader, got: %#v", results)
-	require.True(t, rr.NextRow())
-	require.Equal(t, "1", string(rr.Values()[0]))
-
-	results, err = pipeline.GetResults()
-	require.NoError(t, err)
-	rr, ok = results.(*pgconn.ResultReader)
-	require.Truef(t, ok, "expected ResultReader, got: %#v", results)
-	require.True(t, rr.NextRow())
-	require.Equal(t, "5", string(rr.Values()[0]))
-	require.True(t, rr.NextRow())
-	require.Equal(t, "6", string(rr.Values()[0]))
-
-	err = pipeline.Close()
-	require.NoError(t, err)
-
-	ensureConnValid(t, pgConn)
-}
-
 func TestPipelineCloseReadsUnreadResults(t *testing.T) {
 	t.Parallel()
 
@@ -3811,9 +3609,6 @@ func TestPipelineCloseReadsUnreadResults(t *testing.T) {
 	require.NoError(t, err)
 	defer closeConn(t, pgConn)
 
-	sd, err := pgConn.Prepare(ctx, "ps", "select $1::text as msg", nil)
-	require.NoError(t, err)
-
 	pipeline := pgConn.StartPipeline(ctx)
 	pipeline.SendQueryParams(`select 1`, nil, nil, nil, nil)
 	pipeline.SendQueryParams(`select 2`, nil, nil, nil, nil)
@@ -3826,11 +3621,6 @@ func TestPipelineCloseReadsUnreadResults(t *testing.T) {
 	err = pipeline.Sync()
 	require.NoError(t, err)
 
-	pipeline.SendQueryStatement(sd, [][]byte{[]byte("6")}, nil, nil)
-	pipeline.SendQueryStatement(sd, [][]byte{[]byte("7")}, nil, nil)
-	err = pipeline.Sync()
-	require.NoError(t, err)
-
 	results, err := pipeline.GetResults()
 	require.NoError(t, err)
 	rr, ok := results.(*pgconn.ResultReader)
@@ -4318,8 +4108,6 @@ func TestFatalErrorReceivedInPipelineMode(t *testing.T) {
 	steps = append(steps, pgmock.ExpectAnyMessage(&pgproto3.Describe{}))
 	steps = append(steps, pgmock.ExpectAnyMessage(&pgproto3.Parse{}))
 	steps = append(steps, pgmock.ExpectAnyMessage(&pgproto3.Describe{}))
-	steps = append(steps, pgmock.SendMessage(&pgproto3.ParseComplete{}))
-	steps = append(steps, pgmock.SendMessage(&pgproto3.ParameterDescription{}))
 	steps = append(steps, pgmock.SendMessage(&pgproto3.RowDescription{Fields: []pgproto3.FieldDescription{
 		{Name: []byte("mock")},
 	}}))
diff --git a/query_test.go b/query_test.go
index 34d06444..b9e01b49 100644
--- a/query_test.go
+++ b/query_test.go
@@ -8,7 +8,6 @@ import (
 	"encoding/json"
 	"errors"
 	"fmt"
-	"net"
 	"os"
 	"strconv"
 	"strings"
@@ -2250,80 +2249,6 @@ func TestQueryWithProcedureParametersInAndOut(t *testing.T) {
 	})
 }
 
-type byteCounterConn struct {
-	conn         net.Conn
-	bytesRead    int
-	bytesWritten int
-}
-
-func (cbn *byteCounterConn) Read(b []byte) (n int, err error) {
-	n, err = cbn.conn.Read(b)
-	cbn.bytesRead += n
-	return n, err
-}
-
-func (cbn *byteCounterConn) Write(b []byte) (n int, err error) {
-	n, err = cbn.conn.Write(b)
-	cbn.bytesWritten += n
-	return n, err
-}
-
-func (cbn *byteCounterConn) Close() error {
-	return cbn.conn.Close()
-}
-
-func (cbn *byteCounterConn) LocalAddr() net.Addr {
-	return cbn.conn.LocalAddr()
-}
-
-func (cbn *byteCounterConn) RemoteAddr() net.Addr {
-	return cbn.conn.RemoteAddr()
-}
-
-func (cbn *byteCounterConn) SetDeadline(t time.Time) error {
-	return cbn.conn.SetDeadline(t)
-}
-
-func (cbn *byteCounterConn) SetReadDeadline(t time.Time) error {
-	return cbn.conn.SetReadDeadline(t)
-}
-
-func (cbn *byteCounterConn) SetWriteDeadline(t time.Time) error {
-	return cbn.conn.SetWriteDeadline(t)
-}
-
-func TestQueryNetworkUsage(t *testing.T) {
-	t.Parallel()
-
-	config := mustParseConfig(t, os.Getenv("PGX_TEST_DATABASE"))
-	config.DefaultQueryExecMode = pgx.QueryExecModeCacheStatement
-	var counterConn *byteCounterConn
-	config.AfterNetConnect = func(ctx context.Context, config *pgconn.Config, conn net.Conn) (net.Conn, error) {
-		counterConn = &byteCounterConn{conn: conn}
-		return counterConn, nil
-	}
-
-	conn := mustConnect(t, config)
-	defer closeConn(t, conn)
-
-	pgxtest.SkipCockroachDB(t, conn, "Server uses different number of bytes for same operations")
-
-	counterConn.bytesWritten = 0
-	counterConn.bytesRead = 0
-
-	rows, _ := conn.Query(
-		context.Background(),
-		"select n, 'Adam', 'Smith ' || n, 'male', '1952-06-16'::date, 258, 72, '{foo,bar,baz}'::text[], '2001-01-28 01:02:03-05'::timestamptz from generate_series(100001, 100000 + $1) n",
-		1,
-	)
-	rows.Close()
-	require.NoError(t, rows.Err())
-
-	assert.Equal(t, 413, counterConn.bytesRead)
-	assert.Equal(t, 427, counterConn.bytesWritten)
-	ensureConnValid(t, conn)
-}
-
 // This example uses Query without using any helpers to read the results. Normally CollectRows, ForEachRow, or another
 // helper function should be used.
 func ExampleConn_Query() {
