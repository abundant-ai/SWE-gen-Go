diff --git a/balancer/base/balancer.go b/balancer/base/balancer.go
index 4399ba01..4d576876 100644
--- a/balancer/base/balancer.go
+++ b/balancer/base/balancer.go
@@ -121,7 +121,8 @@ func (b *baseBalancer) UpdateClientConnState(s balancer.ClientConnState) error {
 			sc.Connect()
 		}
 	}
-	for a, sc := range b.subConns.All() {
+	for _, a := range b.subConns.Keys() {
+		sc, _ := b.subConns.Get(a)
 		// a was removed by resolver.
 		if _, ok := addrsSet.Get(a); !ok {
 			sc.Shutdown()
@@ -170,7 +171,8 @@ func (b *baseBalancer) regeneratePicker() {
 	readySCs := make(map[balancer.SubConn]SubConnInfo)
 
 	// Filter out all ready SCs from full subConn map.
-	for addr, sc := range b.subConns.All() {
+	for _, addr := range b.subConns.Keys() {
+		sc, _ := b.subConns.Get(addr)
 		if st, ok := b.scStates[sc]; ok && st == connectivity.Ready {
 			readySCs[sc] = SubConnInfo{Address: addr}
 		}
diff --git a/balancer/endpointsharding/endpointsharding.go b/balancer/endpointsharding/endpointsharding.go
index 12479f69..360db08e 100644
--- a/balancer/endpointsharding/endpointsharding.go
+++ b/balancer/endpointsharding/endpointsharding.go
@@ -187,7 +187,8 @@ func (es *endpointSharding) UpdateClientConnState(state balancer.ClientConnState
 		}
 	}
 	// Delete old children that are no longer present.
-	for e, child := range children.All() {
+	for _, e := range children.Keys() {
+		child, _ := children.Get(e)
 		if _, ok := newChildren.Get(e); !ok {
 			child.closeLocked()
 		}
@@ -211,7 +212,7 @@ func (es *endpointSharding) ResolverError(err error) {
 		es.updateState()
 	}()
 	children := es.children.Load()
-	for _, child := range children.All() {
+	for _, child := range children.Values() {
 		child.resolverErrorLocked(err)
 	}
 }
@@ -224,7 +225,7 @@ func (es *endpointSharding) Close() {
 	es.childMu.Lock()
 	defer es.childMu.Unlock()
 	children := es.children.Load()
-	for _, child := range children.All() {
+	for _, child := range children.Values() {
 		child.closeLocked()
 	}
 }
@@ -232,7 +233,7 @@ func (es *endpointSharding) Close() {
 func (es *endpointSharding) ExitIdle() {
 	es.childMu.Lock()
 	defer es.childMu.Unlock()
-	for _, bw := range es.children.Load().All() {
+	for _, bw := range es.children.Load().Values() {
 		if !bw.isClosed {
 			bw.child.ExitIdle()
 		}
@@ -254,7 +255,7 @@ func (es *endpointSharding) updateState() {
 	children := es.children.Load()
 	childStates := make([]ChildState, 0, children.Len())
 
-	for _, child := range children.All() {
+	for _, child := range children.Values() {
 		childState := child.childState
 		childStates = append(childStates, childState)
 		childPicker := childState.State.Picker
diff --git a/balancer/leastrequest/leastrequest.go b/balancer/leastrequest/leastrequest.go
index 019d1a2c..c7621eea 100644
--- a/balancer/leastrequest/leastrequest.go
+++ b/balancer/leastrequest/leastrequest.go
@@ -180,7 +180,7 @@ func (lrb *leastRequestBalancer) UpdateState(state balancer.State) {
 	}
 
 	// If endpoints are no longer ready, no need to count their active RPCs.
-	for endpoint := range lrb.endpointRPCCounts.All() {
+	for _, endpoint := range lrb.endpointRPCCounts.Keys() {
 		if _, ok := newEndpoints.Get(endpoint); !ok {
 			lrb.endpointRPCCounts.Delete(endpoint)
 		}
diff --git a/balancer/pickfirst/pickfirst.go b/balancer/pickfirst/pickfirst.go
index 2b5026ea..b4bc3a2b 100644
--- a/balancer/pickfirst/pickfirst.go
+++ b/balancer/pickfirst/pickfirst.go
@@ -360,14 +360,14 @@ func (b *pickfirstBalancer) startFirstPassLocked() {
 	b.firstPass = true
 	b.numTF = 0
 	// Reset the connection attempt record for existing SubConns.
-	for _, sd := range b.subConns.All() {
+	for _, sd := range b.subConns.Values() {
 		sd.connectionFailedInFirstPass = false
 	}
 	b.requestConnectionLocked()
 }
 
 func (b *pickfirstBalancer) closeSubConnsLocked() {
-	for _, sd := range b.subConns.All() {
+	for _, sd := range b.subConns.Values() {
 		sd.subConn.Shutdown()
 	}
 	b.subConns = resolver.NewAddressMapV2[*scData]()
@@ -467,7 +467,7 @@ func (b *pickfirstBalancer) reconcileSubConnsLocked(newAddrs []resolver.Address)
 		newAddrsMap.Set(addr, true)
 	}
 
-	for oldAddr := range b.subConns.All() {
+	for _, oldAddr := range b.subConns.Keys() {
 		if _, ok := newAddrsMap.Get(oldAddr); ok {
 			continue
 		}
@@ -481,7 +481,7 @@ func (b *pickfirstBalancer) reconcileSubConnsLocked(newAddrs []resolver.Address)
 // becomes ready, which means that all other subConn must be shutdown.
 func (b *pickfirstBalancer) shutdownRemainingLocked(selected *scData) {
 	b.cancelConnectionTimer()
-	for _, sd := range b.subConns.All() {
+	for _, sd := range b.subConns.Values() {
 		if sd.subConn != selected.subConn {
 			sd.subConn.Shutdown()
 		}
@@ -732,7 +732,7 @@ func (b *pickfirstBalancer) endFirstPassIfPossibleLocked(lastErr error) {
 	}
 	// Connect() has been called on all the SubConns. The first pass can be
 	// ended if all the SubConns have reported a failure.
-	for _, sd := range b.subConns.All() {
+	for _, sd := range b.subConns.Values() {
 		if !sd.connectionFailedInFirstPass {
 			return
 		}
@@ -743,7 +743,7 @@ func (b *pickfirstBalancer) endFirstPassIfPossibleLocked(lastErr error) {
 		Picker:            &picker{err: lastErr},
 	})
 	// Start re-connecting all the SubConns that are already in IDLE.
-	for _, sd := range b.subConns.All() {
+	for _, sd := range b.subConns.Values() {
 		if sd.rawConnectivityState == connectivity.Idle {
 			sd.subConn.Connect()
 		}
diff --git a/balancer/ringhash/ringhash.go b/balancer/ringhash/ringhash.go
index 027b4339..9ff92ada 100644
--- a/balancer/ringhash/ringhash.go
+++ b/balancer/ringhash/ringhash.go
@@ -166,7 +166,7 @@ func (b *ringhashBalancer) UpdateState(state balancer.State) {
 		}
 	}
 
-	for endpoint := range b.endpointStates.All() {
+	for _, endpoint := range b.endpointStates.Keys() {
 		if _, ok := endpointsSet.Get(endpoint); ok {
 			continue
 		}
@@ -261,9 +261,9 @@ func (b *ringhashBalancer) updatePickerLocked() {
 		// non-deterministic, the list of `endpointState`s must be sorted to
 		// ensure `ExitIdle` is called on the same child, preventing unnecessary
 		// connections.
-		var endpointStates = make([]*endpointState, 0, b.endpointStates.Len())
-		for _, s := range b.endpointStates.All() {
-			endpointStates = append(endpointStates, s)
+		var endpointStates = make([]*endpointState, b.endpointStates.Len())
+		for i, s := range b.endpointStates.Values() {
+			endpointStates[i] = s
 		}
 		sort.Slice(endpointStates, func(i, j int) bool {
 			return endpointStates[i].hashKey < endpointStates[j].hashKey
@@ -322,7 +322,7 @@ func (b *ringhashBalancer) ExitIdle() {
 func (b *ringhashBalancer) newPickerLocked() *picker {
 	states := make(map[string]endpointState)
 	hasEndpointConnecting := false
-	for _, epState := range b.endpointStates.All() {
+	for _, epState := range b.endpointStates.Values() {
 		// Copy the endpoint state to avoid races, since ring hash
 		// mutates the state, weight and hash key in place.
 		states[epState.hashKey] = *epState
@@ -356,7 +356,7 @@ func (b *ringhashBalancer) newPickerLocked() *picker {
 // failure to failover to the lower priority.
 func (b *ringhashBalancer) aggregatedStateLocked() connectivity.State {
 	var nums [5]int
-	for _, es := range b.endpointStates.All() {
+	for _, es := range b.endpointStates.Values() {
 		nums[es.state.ConnectivityState]++
 	}
 
diff --git a/balancer/weightedroundrobin/balancer.go b/balancer/weightedroundrobin/balancer.go
index 483b51e8..d7cad7ac 100644
--- a/balancer/weightedroundrobin/balancer.go
+++ b/balancer/weightedroundrobin/balancer.go
@@ -185,7 +185,7 @@ func (b *wrrBalancer) updateEndpointsLocked(endpoints []resolver.Endpoint) {
 		ew.updateConfig(b.cfg)
 	}
 
-	for endpoint := range b.endpointToWeight.All() {
+	for _, endpoint := range b.endpointToWeight.Keys() {
 		if _, ok := endpointSet.Get(endpoint); ok {
 			// Existing endpoint also in new endpoint list; skip.
 			continue
@@ -412,7 +412,7 @@ func (b *wrrBalancer) Close() {
 	b.mu.Unlock()
 
 	// Ensure any lingering OOB watchers are stopped.
-	for _, ew := range b.endpointToWeight.All() {
+	for _, ew := range b.endpointToWeight.Values() {
 		if ew.stopORCAListener != nil {
 			ew.stopORCAListener()
 		}
diff --git a/internal/xds/balancer/outlierdetection/balancer.go b/internal/xds/balancer/outlierdetection/balancer.go
index e47ac406..ff507868 100644
--- a/internal/xds/balancer/outlierdetection/balancer.go
+++ b/internal/xds/balancer/outlierdetection/balancer.go
@@ -251,7 +251,7 @@ func (b *outlierDetectionBalancer) onIntervalConfig() {
 	var interval time.Duration
 	if b.timerStartTime.IsZero() {
 		b.timerStartTime = time.Now()
-		for _, epInfo := range b.endpoints.All() {
+		for _, epInfo := range b.endpoints.Values() {
 			epInfo.callCounter.clear()
 		}
 		interval = time.Duration(b.cfg.Interval)
@@ -274,7 +274,7 @@ func (b *outlierDetectionBalancer) onNoopConfig() {
 	// do the following:"
 	// "Unset the timer start timestamp."
 	b.timerStartTime = time.Time{}
-	for _, epInfo := range b.endpoints.All() {
+	for _, epInfo := range b.endpoints.Values() {
 		// "Uneject all currently ejected endpoints."
 		if !epInfo.latestEjectionTimestamp.IsZero() {
 			b.unejectEndpoint(epInfo)
@@ -326,7 +326,7 @@ func (b *outlierDetectionBalancer) UpdateClientConnState(s balancer.ClientConnSt
 		}
 	}
 
-	for ep := range b.endpoints.All() {
+	for _, ep := range b.endpoints.Keys() {
 		if _, ok := newEndpoints.Get(ep); !ok {
 			b.endpoints.Delete(ep)
 		}
@@ -657,7 +657,7 @@ func (b *outlierDetectionBalancer) intervalTimerAlgorithm() {
 	defer b.mu.Unlock()
 	b.timerStartTime = time.Now()
 
-	for _, epInfo := range b.endpoints.All() {
+	for _, epInfo := range b.endpoints.Values() {
 		epInfo.callCounter.swap()
 	}
 
@@ -669,7 +669,7 @@ func (b *outlierDetectionBalancer) intervalTimerAlgorithm() {
 		b.failurePercentageAlgorithm()
 	}
 
-	for _, epInfo := range b.endpoints.All() {
+	for _, epInfo := range b.endpoints.Values() {
 		if epInfo.latestEjectionTimestamp.IsZero() && epInfo.ejectionTimeMultiplier > 0 {
 			epInfo.ejectionTimeMultiplier--
 			continue
@@ -701,7 +701,7 @@ func (b *outlierDetectionBalancer) intervalTimerAlgorithm() {
 // Caller must hold b.mu.
 func (b *outlierDetectionBalancer) endpointsWithAtLeastRequestVolume(requestVolume uint32) []*endpointInfo {
 	var endpoints []*endpointInfo
-	for _, epInfo := range b.endpoints.All() {
+	for _, epInfo := range b.endpoints.Values() {
 		bucket1 := epInfo.callCounter.inactiveBucket
 		rv := bucket1.numSuccesses + bucket1.numFailures
 		if rv >= requestVolume {
diff --git a/resolver/map.go b/resolver/map.go
index 789a5aba..c3c15ac9 100644
--- a/resolver/map.go
+++ b/resolver/map.go
@@ -20,7 +20,6 @@ package resolver
 
 import (
 	"encoding/base64"
-	"iter"
 	"sort"
 	"strings"
 )
@@ -136,7 +135,6 @@ func (a *AddressMapV2[T]) Len() int {
 }
 
 // Keys returns a slice of all current map keys.
-// Deprecated: Use AddressMapV2.All() instead.
 func (a *AddressMapV2[T]) Keys() []Address {
 	ret := make([]Address, 0, a.Len())
 	for _, entryList := range a.m {
@@ -148,7 +146,6 @@ func (a *AddressMapV2[T]) Keys() []Address {
 }
 
 // Values returns a slice of all current map values.
-// Deprecated: Use AddressMapV2.All() instead.
 func (a *AddressMapV2[T]) Values() []T {
 	ret := make([]T, 0, a.Len())
 	for _, entryList := range a.m {
@@ -159,19 +156,6 @@ func (a *AddressMapV2[T]) Values() []T {
 	return ret
 }
 
-// All returns an iterator over all elements.
-func (a *AddressMapV2[T]) All() iter.Seq2[Address, T] {
-	return func(yield func(Address, T) bool) {
-		for _, entryList := range a.m {
-			for _, entry := range entryList {
-				if !yield(entry.addr, entry.value) {
-					return
-				}
-			}
-		}
-	}
-}
-
 type endpointMapKey string
 
 // EndpointMap is a map of endpoints to arbitrary values keyed on only the
@@ -239,7 +223,6 @@ func (em *EndpointMap[T]) Len() int {
 // the unordered set of addresses. Thus, endpoint information returned is not
 // the full endpoint data (drops duplicated addresses and attributes) but can be
 // used for EndpointMap accesses.
-// Deprecated: Use EndpointMap.All() instead.
 func (em *EndpointMap[T]) Keys() []Endpoint {
 	ret := make([]Endpoint, 0, len(em.endpoints))
 	for _, en := range em.endpoints {
@@ -249,7 +232,6 @@ func (em *EndpointMap[T]) Keys() []Endpoint {
 }
 
 // Values returns a slice of all current map values.
-// Deprecated: Use EndpointMap.All() instead.
 func (em *EndpointMap[T]) Values() []T {
 	ret := make([]T, 0, len(em.endpoints))
 	for _, val := range em.endpoints {
@@ -258,22 +240,6 @@ func (em *EndpointMap[T]) Values() []T {
 	return ret
 }
 
-// All returns an iterator over all elements.
-// The map keys are endpoints specifying the addresses present in the endpoint
-// map, in which uniqueness is determined by the unordered set of addresses.
-// Thus, endpoint information returned is not the full endpoint data (drops
-// duplicated addresses and attributes) but can be used for EndpointMap
-// accesses.
-func (em *EndpointMap[T]) All() iter.Seq2[Endpoint, T] {
-	return func(yield func(Endpoint, T) bool) {
-		for _, en := range em.endpoints {
-			if !yield(en.decodedKey, en.value) {
-				return
-			}
-		}
-	}
-}
-
 // Delete removes the specified endpoint from the map.
 func (em *EndpointMap[T]) Delete(e Endpoint) {
 	en := encodeEndpoint(e)
diff --git a/resolver/map_test.go b/resolver/map_test.go
index 55b4fffd..33526839 100644
--- a/resolver/map_test.go
+++ b/resolver/map_test.go
@@ -170,35 +170,6 @@ func (s) TestAddressMap_Values(t *testing.T) {
 	}
 }
 
-func (s) TestAddressMap_All(t *testing.T) {
-	addrMap := NewAddressMapV2[int]()
-	addrMap.Set(addr1, 1)
-	addrMap.Set(addr2, 2)
-	addrMap.Set(addr3, 3)
-	addrMap.Set(addr4, 4)
-	addrMap.Set(addr5, 5)
-	addrMap.Set(addr6, 6)
-	addrMap.Set(addr7, 7) // aliases addr1
-
-	type pair struct {
-		K Address
-		V int
-	}
-
-	want := []pair{{addr1, 7}, {addr2, 2}, {addr3, 3}, {addr4, 4}, {addr5, 5}, {addr6, 6}}
-	var got []pair
-	for k, v := range addrMap.All() {
-		got = append(got, pair{k, v})
-	}
-	if d := cmp.Diff(want, got, cmp.Transformer("sort", func(in []pair) []pair {
-		out := append([]pair(nil), in...)
-		sort.Slice(out, func(i, j int) bool { return out[i].V < out[j].V })
-		return out
-	})); d != "" {
-		t.Fatalf("addrMap.All returned unexpected elements (-want, +got):\n%v", d)
-	}
-}
-
 func (s) TestEndpointMap_Length(t *testing.T) {
 	em := NewEndpointMap[struct{}]()
 	// Should be empty at creation time.
@@ -311,37 +282,6 @@ func (s) TestEndpointMap_Values(t *testing.T) {
 	}
 }
 
-func (s) TestEndpointMap_All(t *testing.T) {
-	em := NewEndpointMap[int]()
-	em.Set(endpoint1, 1)
-	// The second endpoint endpoint21 should override.
-	em.Set(endpoint12, 1)
-	em.Set(endpoint21, 2)
-	em.Set(endpoint3, 3)
-	em.Set(endpoint4, 4)
-	em.Set(endpoint5, 5)
-	em.Set(endpoint6, 6)
-	em.Set(endpoint7, 7)
-
-	type pair struct {
-		K Endpoint
-		V int
-	}
-
-	want := []pair{{endpoint1, 1}, {endpoint21, 2}, {endpoint3, 3}, {endpoint4, 4}, {endpoint5, 5}, {endpoint6, 6}, {endpoint7, 7}}
-	var got []pair
-	for k, v := range em.All() {
-		got = append(got, pair{k, v})
-	}
-	if d := cmp.Diff(want, got, cmp.Transformer("sort", func(in []pair) []pair {
-		out := append([]pair(nil), in...)
-		sort.Slice(out, func(i, j int) bool { return out[i].V < out[j].V })
-		return out
-	})); d != "" {
-		t.Fatalf("em.All returned unexpected elements (-want, +got):\n%v", d)
-	}
-}
-
 // BenchmarkEndpointMap benchmarks map operations that are expected to run
 // faster than O(n). This test doesn't run O(n) operations including listing
 // keys and values.
