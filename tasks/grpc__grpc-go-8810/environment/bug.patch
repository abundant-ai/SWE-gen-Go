diff --git a/internal/xds/balancer/outlierdetection/balancer.go b/internal/xds/balancer/outlierdetection/balancer.go
index ff507868..d6c8c6de 100644
--- a/internal/xds/balancer/outlierdetection/balancer.go
+++ b/internal/xds/balancer/outlierdetection/balancer.go
@@ -457,11 +457,19 @@ func incrementCounter(sc balancer.SubConn, info balancer.DoneInfo) {
 		return
 	}
 
-	// After reading callCounter.activeBucket in this picker a swap call can
-	// concurrently change what activeBucket points to. A50 says to swap the
-	// pointer, which will cause this race to write to deprecated memory the
-	// interval timer algorithm will never read, which makes this race alright.
-	epInfo := scw.endpointInfo
+	// scw.endpointInfo and callCounter.activeBucket can be written to
+	// concurrently (the pointers themselves). Thus, protect the reads here with
+	// atomics to prevent data corruption. There exists a race in which you read
+	// the endpointInfo or active bucket pointer and then that pointer points to
+	// deprecated memory. If this goroutine yields the processor, in between
+	// reading the endpointInfo pointer and writing to the active bucket,
+	// UpdateAddresses can switch the endpointInfo the scw points to. Writing to
+	// an outdated endpoint is a very small race and tolerable. After reading
+	// callCounter.activeBucket in this picker a swap call can concurrently
+	// change what activeBucket points to. A50 says to swap the pointer, which
+	// will cause this race to write to deprecated memory the interval timer
+	// algorithm will never read, which makes this race alright.
+	epInfo := scw.endpointInfo.Load()
 	if epInfo == nil {
 		return
 	}
@@ -502,7 +510,7 @@ func (b *outlierDetectionBalancer) NewSubConn(addrs []resolver.Address, opts bal
 		return scw, nil
 	}
 	epInfo.sws = append(epInfo.sws, scw)
-	scw.endpointInfo = epInfo
+	scw.endpointInfo.Store(epInfo)
 	if !epInfo.latestEjectionTimestamp.IsZero() {
 		scw.eject()
 	}
@@ -513,12 +521,28 @@ func (b *outlierDetectionBalancer) RemoveSubConn(sc balancer.SubConn) {
 	b.logger.Errorf("RemoveSubConn(%v) called unexpectedly", sc)
 }
 
+// appendIfPresent appends the scw to the endpoint, if the address is present in
+// the Outlier Detection balancers address map. Returns nil if not present, and
+// the map entry if present.
+//
+// Caller must hold b.mu.
+func (b *outlierDetectionBalancer) appendIfPresent(addr string, scw *subConnWrapper) *endpointInfo {
+	epInfo, ok := b.addrs[addr]
+	if !ok {
+		return nil
+	}
+
+	epInfo.sws = append(epInfo.sws, scw)
+	scw.endpointInfo.Store(epInfo)
+	return epInfo
+}
+
 // removeSubConnFromEndpointMapEntry removes the scw from its map entry if
 // present.
 //
 // Caller must hold b.mu.
 func (b *outlierDetectionBalancer) removeSubConnFromEndpointMapEntry(scw *subConnWrapper) {
-	epInfo := scw.endpointInfo
+	epInfo := scw.endpointInfo.Load()
 	if epInfo == nil {
 		return
 	}
@@ -530,20 +554,61 @@ func (b *outlierDetectionBalancer) removeSubConnFromEndpointMapEntry(scw *subCon
 	}
 }
 
-func (b *outlierDetectionBalancer) UpdateAddresses(sc balancer.SubConn, _ []resolver.Address) {
-	b.logger.Errorf("UpdateAddresses(%v) called unexpectedly", sc)
+func (b *outlierDetectionBalancer) UpdateAddresses(sc balancer.SubConn, addrs []resolver.Address) {
+	scw, ok := sc.(*subConnWrapper)
+	if !ok {
+		// Return, shouldn't happen if passed up scw
+		return
+	}
+
+	b.ClientConn.UpdateAddresses(scw.SubConn, addrs)
+	b.mu.Lock()
+	defer b.mu.Unlock()
+
+	// Note that 0 addresses is a valid update/state for a SubConn to be in.
+	// This is correctly handled by this algorithm (handled as part of a non singular
+	// old address/new address).
+	switch {
+	case len(scw.addresses) == 1 && len(addrs) == 1: // single address to single address
+		// If the updated address is the same, then there is nothing to do
+		// past this point.
+		if scw.addresses[0].Addr == addrs[0].Addr {
+			return
+		}
+		b.removeSubConnFromEndpointMapEntry(scw)
+		endpointInfo := b.appendIfPresent(addrs[0].Addr, scw)
+		if endpointInfo == nil { // uneject unconditionally because could have come from an ejected endpoint
+			scw.uneject()
+			break
+		}
+		if endpointInfo.latestEjectionTimestamp.IsZero() { // relay new updated subconn state
+			scw.uneject()
+		} else {
+			scw.eject()
+		}
+	case len(scw.addresses) == 1: // single address to multiple/no addresses
+		b.removeSubConnFromEndpointMapEntry(scw)
+		addrInfo := scw.endpointInfo.Load()
+		if addrInfo != nil {
+			addrInfo.callCounter.clear()
+		}
+		scw.uneject()
+	case len(addrs) == 1: // multiple/no addresses to single address
+		endpointInfo := b.appendIfPresent(addrs[0].Addr, scw)
+		if endpointInfo != nil && !endpointInfo.latestEjectionTimestamp.IsZero() {
+			scw.eject()
+		}
+	} // otherwise multiple/no addresses to multiple/no addresses; ignore
+
+	scw.addresses = addrs
 }
 
-// handleSubConnUpdate stores the recent state and forward the update.
+// handleSubConnUpdate stores the recent state and forward the update
+// if the SubConn is not ejected.
 func (b *outlierDetectionBalancer) handleSubConnUpdate(u *scUpdate) {
 	scw := u.scw
 	scw.clearHealthListener()
 	b.child.updateSubConnState(scw, u.state)
-	if u.state.ConnectivityState == connectivity.Shutdown {
-		b.mu.Lock()
-		b.removeSubConnFromEndpointMapEntry(scw)
-		b.mu.Unlock()
-	}
 }
 
 func (b *outlierDetectionBalancer) handleSubConnHealthUpdate(u *scHealthUpdate) {
diff --git a/internal/xds/balancer/outlierdetection/balancer_test.go b/internal/xds/balancer/outlierdetection/balancer_test.go
index 06c48674..cf6a2916 100644
--- a/internal/xds/balancer/outlierdetection/balancer_test.go
+++ b/internal/xds/balancer/outlierdetection/balancer_test.go
@@ -680,6 +680,225 @@ func (s) TestChildBasicOperations(t *testing.T) {
 	}
 }
 
+// TestUpdateAddresses tests the functionality of UpdateAddresses and any
+// changes in the addresses/plurality of those addresses for a SubConn. The
+// Balancer is set up with two upstreams, with one of the upstreams being
+// ejected. Initially, there is one SubConn for each address. The following
+// scenarios are tested, in a step by step fashion:
+// 1. The SubConn not currently ejected switches addresses to the address that
+// is ejected. This should cause the SubConn to get ejected.
+// 2. Update this same SubConn to multiple addresses. This should cause the
+// SubConn to get unejected, as it is no longer being tracked by Outlier
+// Detection at that point.
+// 3. Update this same SubConn to different addresses, still multiple. This
+// should be a noop, as the SubConn is still no longer being tracked by Outlier
+// Detection.
+// 4. Update this same SubConn to the a single address which is ejected. This
+// should cause the SubConn to be ejected.
+func (s) TestUpdateAddresses(t *testing.T) {
+	scsCh := testutils.NewChannel()
+	var scw1, scw2 balancer.SubConn
+	var err error
+	connectivityCh := make(chan struct{})
+	stub.Register(t.Name(), stub.BalancerFuncs{
+		UpdateClientConnState: func(bd *stub.BalancerData, _ balancer.ClientConnState) error {
+			scw1, err = bd.ClientConn.NewSubConn([]resolver.Address{{Addr: "address1"}}, balancer.NewSubConnOptions{
+				StateListener: func(balancer.SubConnState) {},
+			})
+			if err != nil {
+				t.Errorf("error in od.NewSubConn call: %v", err)
+			}
+			scw1.Connect()
+			scw2, err = bd.ClientConn.NewSubConn([]resolver.Address{{Addr: "address2"}}, balancer.NewSubConnOptions{
+				StateListener: func(state balancer.SubConnState) {
+					if state.ConnectivityState == connectivity.Ready {
+						close(connectivityCh)
+					}
+				},
+			})
+			if err != nil {
+				t.Errorf("error in od.NewSubConn call: %v", err)
+			}
+			scw2.Connect()
+			bd.ClientConn.UpdateState(balancer.State{
+				ConnectivityState: connectivity.Ready,
+				Picker: &rrPicker{
+					scs: []balancer.SubConn{scw1, scw2},
+				},
+			})
+			return nil
+		},
+	})
+
+	od, tcc, cleanup := setup(t)
+	defer cleanup()
+
+	od.UpdateClientConnState(balancer.ClientConnState{
+		ResolverState: resolver.State{
+			Endpoints: []resolver.Endpoint{
+				{Addresses: []resolver.Address{{Addr: "address1"}}},
+				{Addresses: []resolver.Address{{Addr: "address2"}}},
+			},
+		},
+		BalancerConfig: &LBConfig{
+			Interval:           iserviceconfig.Duration(10 * time.Second),
+			BaseEjectionTime:   iserviceconfig.Duration(30 * time.Second),
+			MaxEjectionTime:    iserviceconfig.Duration(300 * time.Second),
+			MaxEjectionPercent: 10,
+			FailurePercentageEjection: &FailurePercentageEjection{
+				Threshold:             50,
+				EnforcementPercentage: 100,
+				MinimumHosts:          2,
+				RequestVolume:         3,
+			},
+			ChildPolicy: &iserviceconfig.BalancerConfig{
+				Name:   t.Name(),
+				Config: emptyChildConfig{},
+			},
+		},
+	})
+
+	ctx, cancel := context.WithTimeout(context.Background(), defaultTestTimeout)
+	defer cancel()
+
+	// Transition SubConns to READY so that they can register a health listener.
+	for range 2 {
+		select {
+		case <-ctx.Done():
+			t.Fatalf("Timed out waiting for creation of new SubConn.")
+		case sc := <-tcc.NewSubConnCh:
+			sc.UpdateState(balancer.SubConnState{ConnectivityState: connectivity.Connecting})
+			sc.UpdateState(balancer.SubConnState{ConnectivityState: connectivity.Ready})
+		}
+	}
+
+	// Register health listeners after all the connectivity updates are
+	// processed to avoid data races while accessing the health listener within
+	// the TestClientConn.
+	select {
+	case <-ctx.Done():
+		t.Fatal("Context timed out waiting for all SubConns to become READY.")
+	case <-connectivityCh:
+	}
+
+	scw1.RegisterHealthListener(func(healthState balancer.SubConnState) {
+		scsCh.Send(subConnWithState{sc: scw1, state: healthState})
+	})
+	scw2.RegisterHealthListener(func(healthState balancer.SubConnState) {
+		scsCh.Send(subConnWithState{sc: scw2, state: healthState})
+	})
+
+	// Setup the system to where one address is ejected and one address
+	// isn't.
+	select {
+	case <-ctx.Done():
+		t.Fatal("timeout while waiting for a UpdateState call on the ClientConn")
+	case picker := <-tcc.NewPickerCh:
+		pi, err := picker.Pick(balancer.PickInfo{})
+		if err != nil {
+			t.Fatalf("picker.Pick failed with error: %v", err)
+		}
+		// Simulate 5 successful RPC calls on the first SubConn (the first call
+		// to picker.Pick).
+		for c := 0; c < 5; c++ {
+			pi.Done(balancer.DoneInfo{})
+		}
+		pi, err = picker.Pick(balancer.PickInfo{})
+		if err != nil {
+			t.Fatalf("picker.Pick failed with error: %v", err)
+		}
+		// Simulate 5 failed RPC calls on the second SubConn (the second call to
+		// picker.Pick). Thus, when the interval timer algorithm is run, the
+		// second SubConn's address should be ejected, which will allow us to
+		// further test UpdateAddresses() logic.
+		for c := 0; c < 5; c++ {
+			pi.Done(balancer.DoneInfo{Err: errors.New("some error")})
+		}
+		od.intervalTimerAlgorithm()
+		// verify StateListener() got called with TRANSIENT_FAILURE for child
+		// with address that was ejected.
+		gotSCWS, err := scsCh.Receive(ctx)
+		if err != nil {
+			t.Fatalf("Error waiting for Sub Conn update: %v", err)
+		}
+		if err = scwsEqual(gotSCWS.(subConnWithState), subConnWithState{
+			sc:    scw2,
+			state: balancer.SubConnState{ConnectivityState: connectivity.TransientFailure},
+		}); err != nil {
+			t.Fatalf("Error in Sub Conn update: %v", err)
+		}
+	}
+
+	// Update scw1 to another address that is currently ejected. This should
+	// cause scw1 to get ejected.
+	od.UpdateAddresses(scw1, []resolver.Address{{Addr: "address2"}})
+
+	// Verify that update addresses gets forwarded to ClientConn.
+	select {
+	case <-ctx.Done():
+		t.Fatal("timeout while waiting for a UpdateState call on the ClientConn")
+	case <-tcc.UpdateAddressesAddrsCh:
+	}
+	// Verify scw1 got ejected (StateListener called with TRANSIENT_FAILURE).
+	gotSCWS, err := scsCh.Receive(ctx)
+	if err != nil {
+		t.Fatalf("Error waiting for Sub Conn update: %v", err)
+	}
+	if err = scwsEqual(gotSCWS.(subConnWithState), subConnWithState{
+		sc:    scw1,
+		state: balancer.SubConnState{ConnectivityState: connectivity.TransientFailure},
+	}); err != nil {
+		t.Fatalf("Error in Sub Conn update: %v", err)
+	}
+
+	// Update scw1 to multiple addresses. This should cause scw1 to get
+	// unejected, as is it no longer being tracked for Outlier Detection.
+	od.UpdateAddresses(scw1, []resolver.Address{
+		{Addr: "address1"},
+		{Addr: "address2"},
+	})
+	// Verify scw1 got unejected (StateListener called with recent state).
+	gotSCWS, err = scsCh.Receive(ctx)
+	if err != nil {
+		t.Fatalf("Error waiting for Sub Conn update: %v", err)
+	}
+	if err = scwsEqual(gotSCWS.(subConnWithState), subConnWithState{
+		sc:    scw1,
+		state: balancer.SubConnState{ConnectivityState: connectivity.Connecting},
+	}); err != nil {
+		t.Fatalf("Error in Sub Conn update: %v", err)
+	}
+
+	// Update scw1 to a different multiple addresses list. A change of addresses
+	// in which the plurality goes from multiple to multiple should be a no-op,
+	// as the address continues to be ignored by outlier detection.
+	od.UpdateAddresses(scw1, []resolver.Address{
+		{Addr: "address2"},
+		{Addr: "address3"},
+	})
+	// Verify no downstream effects.
+	sCtx, cancel := context.WithTimeout(context.Background(), defaultTestShortTimeout)
+	defer cancel()
+	if _, err := scsCh.Receive(sCtx); err == nil {
+		t.Fatalf("no SubConn update should have been sent (no SubConn got ejected/unejected)")
+	}
+
+	// Update scw1 back to a single address, which is ejected. This should cause
+	// the SubConn to be re-ejected.
+	od.UpdateAddresses(scw1, []resolver.Address{{Addr: "address2"}})
+	// Verify scw1 got ejected (StateListener called with TRANSIENT FAILURE).
+	gotSCWS, err = scsCh.Receive(ctx)
+	if err != nil {
+		t.Fatalf("Error waiting for Sub Conn update: %v", err)
+	}
+	if err = scwsEqual(gotSCWS.(subConnWithState), subConnWithState{
+		sc:    scw1,
+		state: balancer.SubConnState{ConnectivityState: connectivity.TransientFailure},
+	}); err != nil {
+		t.Fatalf("Error in Sub Conn update: %v", err)
+	}
+}
+
 func scwsEqual(gotSCWS subConnWithState, wantSCWS subConnWithState) error {
 	if gotSCWS.sc != wantSCWS.sc || !cmp.Equal(gotSCWS.state, wantSCWS.state, cmp.AllowUnexported(subConnWrapper{}, endpointInfo{}, balancer.SubConnState{}), cmpopts.IgnoreFields(subConnWrapper{}, "scUpdateCh")) {
 		return fmt.Errorf("received SubConnState: %+v, want %+v", gotSCWS, wantSCWS)
@@ -1554,6 +1773,12 @@ func (s) TestConcurrentOperations(t *testing.T) {
 		scw1.Shutdown()
 	}()
 
+	wg.Add(1)
+	go func() {
+		defer wg.Done()
+		od.UpdateAddresses(scw2, []resolver.Address{{Addr: "address3"}})
+	}()
+
 	// Call balancer.Balancers synchronously in this goroutine, upholding the
 	// balancer.Balancer API guarantee of synchronous calls.
 	od.UpdateClientConnState(balancer.ClientConnState{ // This will delete addresses and flip to no op
@@ -1994,106 +2219,3 @@ func (s) TestEjectionStateResetsWhenEndpointAddressesChange(t *testing.T) {
 		t.Fatalf("RPCs didn't go to the second addresses of both endpoints: %v", err)
 	}
 }
-
-// TestSubConnShutdownRemovesFromEndpointMap tests that when a subconn is shut
-// down, it's removed from the endpoint map.
-func (s) TestSubConnShutdownRemovesFromEndpointMap(t *testing.T) {
-	childBalancerUpdateCh := testutils.NewChannel()
-	childBalancerNewSubConnCh := testutils.NewChannel()
-
-	stub.Register(t.Name(), stub.BalancerFuncs{
-		UpdateClientConnState: func(bd *stub.BalancerData, ccs balancer.ClientConnState) error {
-			var sc balancer.SubConn
-			opts := balancer.NewSubConnOptions{
-				StateListener: func(scs balancer.SubConnState) {
-					childBalancerUpdateCh.Send(subConnWithState{sc: sc, state: scs})
-				},
-			}
-			sc, err := bd.ClientConn.NewSubConn(ccs.ResolverState.Endpoints[0].Addresses, opts)
-			if err != nil {
-				return err
-			}
-			childBalancerNewSubConnCh.Send(sc)
-			sc.Connect()
-			return nil
-		},
-	})
-
-	od, tcc, cleanup := setup(t)
-	defer cleanup()
-
-	addr := "address1"
-	ep := resolver.Endpoint{Addresses: []resolver.Address{{Addr: addr}}}
-	od.UpdateClientConnState(balancer.ClientConnState{
-		ResolverState: resolver.State{
-			Endpoints: []resolver.Endpoint{ep},
-		},
-		BalancerConfig: &LBConfig{
-			ChildPolicy: &iserviceconfig.BalancerConfig{
-				Name:   t.Name(),
-				Config: emptyChildConfig{},
-			},
-		},
-	})
-
-	ctx, cancel := context.WithTimeout(context.Background(), defaultTestTimeout)
-	defer cancel()
-
-	// The child balancer creates a subconn.
-	sc, err := childBalancerNewSubConnCh.Receive(ctx)
-	if err != nil {
-		t.Fatalf("Timeout waiting for child balancer to create a subconn: %v", err)
-	}
-	scw := sc.(*subConnWrapper)
-
-	// The OD balancer creates an underlying subconn.
-	testSC := <-tcc.NewSubConnCh
-
-	// Verify the subconn wrapper is in the endpoint info.
-	od.mu.Lock()
-	epInfo, ok := od.endpoints.Get(ep)
-	if !ok {
-		od.mu.Unlock()
-		t.Fatalf("epInfo not found for endpoint %v", ep)
-	}
-	if len(epInfo.sws) != 1 || epInfo.sws[0] != scw {
-		od.mu.Unlock()
-		t.Fatalf("subConnWrapper not found in endpointInfo.sws, got: %v", epInfo.sws)
-	}
-	od.mu.Unlock()
-
-	// Simulate SHUTDOWN state update for the subconn. This is done by calling
-	// UpdateState on the underlying TestSubConn.
-	testSC.UpdateState(balancer.SubConnState{ConnectivityState: connectivity.Shutdown})
-
-	// The OD balancer will forward this update to the child.
-	update, err := childBalancerUpdateCh.Receive(ctx)
-	if err != nil {
-		t.Fatalf("Timeout waiting for child balancer to receive subconn update: %v", err)
-	}
-	gotUpdate := update.(subConnWithState)
-	if gotUpdate.sc != scw {
-		t.Fatalf("Child balancer received update for unexpected subconn: got %v, want %v", gotUpdate.sc, scw)
-	}
-	if gotUpdate.state.ConnectivityState != connectivity.Shutdown {
-		t.Fatalf("Child balancer received unexpected subconn state: got %v, want %v", gotUpdate.state.ConnectivityState, connectivity.Shutdown)
-	}
-
-	// Now we need to verify that the subconn wrapper is removed.
-	// We'll poll for a short time.
-	for {
-		select {
-		case <-ctx.Done():
-			t.Fatalf("Timed out waiting for subconn to be removed from endpoint map")
-		default:
-		}
-		od.mu.Lock()
-		epInfo, _ := od.endpoints.Get(ep)
-		if epInfo == nil || len(epInfo.sws) == 0 {
-			od.mu.Unlock()
-			return // Success
-		}
-		od.mu.Unlock()
-		<-time.After(time.Millisecond)
-	}
-}
diff --git a/internal/xds/balancer/outlierdetection/subconn_wrapper.go b/internal/xds/balancer/outlierdetection/subconn_wrapper.go
index bff67741..b893ea68 100644
--- a/internal/xds/balancer/outlierdetection/subconn_wrapper.go
+++ b/internal/xds/balancer/outlierdetection/subconn_wrapper.go
@@ -20,6 +20,7 @@ package outlierdetection
 import (
 	"fmt"
 	"sync"
+	"sync/atomic"
 
 	"google.golang.org/grpc/balancer"
 	"google.golang.org/grpc/connectivity"
@@ -33,8 +34,8 @@ import (
 type subConnWrapper struct {
 	balancer.SubConn
 	// endpointInfo is a pointer to the subConnWrapper's corresponding endpoint
-	// map entry, if the map entry exists.
-	endpointInfo *endpointInfo
+	// map entry, if the map entry exists. It is accessed atomically.
+	endpointInfo atomic.Pointer[endpointInfo]
 	// The following fields are set during object creation and read-only after
 	// that.
 
