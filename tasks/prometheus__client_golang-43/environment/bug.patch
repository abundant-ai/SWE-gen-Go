diff --git a/extraction/metricfamilyprocessor.go b/extraction/metricfamilyprocessor.go
index af2bea6..1be6432 100644
--- a/extraction/metricfamilyprocessor.go
+++ b/extraction/metricfamilyprocessor.go
@@ -101,7 +101,7 @@ func extractCounter(out Ingester, o *ProcessOptions, f *dto.MetricFamily) error
 		sample.Value = model.SampleValue(m.Counter.GetValue())
 	}
 
-	return out.Ingest(samples)
+	return out.Ingest(&Result{Samples: samples})
 }
 
 func extractGauge(out Ingester, o *ProcessOptions, f *dto.MetricFamily) error {
@@ -132,7 +132,7 @@ func extractGauge(out Ingester, o *ProcessOptions, f *dto.MetricFamily) error {
 		sample.Value = model.SampleValue(m.Gauge.GetValue())
 	}
 
-	return out.Ingest(samples)
+	return out.Ingest(&Result{Samples: samples})
 }
 
 func extractSummary(out Ingester, o *ProcessOptions, f *dto.MetricFamily) error {
@@ -194,7 +194,7 @@ func extractSummary(out Ingester, o *ProcessOptions, f *dto.MetricFamily) error
 		}
 	}
 
-	return out.Ingest(samples)
+	return out.Ingest(&Result{Samples: samples})
 }
 
 func extractUntyped(out Ingester, o *ProcessOptions, f *dto.MetricFamily) error {
@@ -225,5 +225,5 @@ func extractUntyped(out Ingester, o *ProcessOptions, f *dto.MetricFamily) error
 		sample.Value = model.SampleValue(m.Untyped.GetValue())
 	}
 
-	return out.Ingest(samples)
+	return out.Ingest(&Result{Samples: samples})
 }
diff --git a/extraction/metricfamilyprocessor_test.go b/extraction/metricfamilyprocessor_test.go
index c4ffe90..7bc6c7e 100644
--- a/extraction/metricfamilyprocessor_test.go
+++ b/extraction/metricfamilyprocessor_test.go
@@ -25,11 +25,11 @@ var testTime = model.Now()
 
 type metricFamilyProcessorScenario struct {
 	in               string
-	expected, actual []model.Samples
+	expected, actual []*Result
 }
 
-func (s *metricFamilyProcessorScenario) Ingest(samples model.Samples) error {
-	s.actual = append(s.actual, samples)
+func (s *metricFamilyProcessorScenario) Ingest(r *Result) error {
+	s.actual = append(s.actual, r)
 	return nil
 }
 
@@ -50,10 +50,10 @@ func (s *metricFamilyProcessorScenario) test(t *testing.T, set int) {
 	}
 
 	for i, expected := range s.expected {
-		sort.Sort(s.actual[i])
-		sort.Sort(expected)
+		sort.Sort(s.actual[i].Samples)
+		sort.Sort(expected.Samples)
 
-		if !expected.Equal(s.actual[i]) {
+		if !expected.equal(s.actual[i]) {
 			t.Errorf("%d.%d. expected %s, got %s", set, i, expected, s.actual[i])
 		}
 	}
@@ -66,39 +66,43 @@ func TestMetricFamilyProcessor(t *testing.T) {
 		},
 		{
 			in: "\x8f\x01\n\rrequest_count\x12\x12Number of requests\x18\x00\"0\n#\n\x0fsome_label_name\x12\x10some_label_value\x1a\t\t\x00\x00\x00\x00\x00\x00E\xc0\"6\n)\n\x12another_label_name\x12\x13another_label_value\x1a\t\t\x00\x00\x00\x00\x00\x00U@",
-			expected: []model.Samples{
-				model.Samples{
-					&model.Sample{
-						Metric:    model.Metric{model.MetricNameLabel: "request_count", "some_label_name": "some_label_value"},
-						Value:     -42,
-						Timestamp: testTime,
-					},
-					&model.Sample{
-						Metric:    model.Metric{model.MetricNameLabel: "request_count", "another_label_name": "another_label_value"},
-						Value:     84,
-						Timestamp: testTime,
+			expected: []*Result{
+				{
+					Samples: model.Samples{
+						&model.Sample{
+							Metric:    model.Metric{model.MetricNameLabel: "request_count", "some_label_name": "some_label_value"},
+							Value:     -42,
+							Timestamp: testTime,
+						},
+						&model.Sample{
+							Metric:    model.Metric{model.MetricNameLabel: "request_count", "another_label_name": "another_label_value"},
+							Value:     84,
+							Timestamp: testTime,
+						},
 					},
 				},
 			},
 		},
 		{
 			in: "\xb9\x01\n\rrequest_count\x12\x12Number of requests\x18\x02\"O\n#\n\x0fsome_label_name\x12\x10some_label_value\"(\x1a\x12\t\xaeG\xe1z\x14\xae\xef?\x11\x00\x00\x00\x00\x00\x00E\xc0\x1a\x12\t+\x87\x16\xd9\xce\xf7\xef?\x11\x00\x00\x00\x00\x00\x00U\xc0\"A\n)\n\x12another_label_name\x12\x13another_label_value\"\x14\x1a\x12\t\x00\x00\x00\x00\x00\x00\xe0?\x11\x00\x00\x00\x00\x00\x00$@",
-			expected: []model.Samples{
-				model.Samples{
-					&model.Sample{
-						Metric:    model.Metric{model.MetricNameLabel: "request_count", "some_label_name": "some_label_value", "quantile": "0.99"},
-						Value:     -42,
-						Timestamp: testTime,
-					},
-					&model.Sample{
-						Metric:    model.Metric{model.MetricNameLabel: "request_count", "some_label_name": "some_label_value", "quantile": "0.999"},
-						Value:     -84,
-						Timestamp: testTime,
-					},
-					&model.Sample{
-						Metric:    model.Metric{model.MetricNameLabel: "request_count", "another_label_name": "another_label_value", "quantile": "0.5"},
-						Value:     10,
-						Timestamp: testTime,
+			expected: []*Result{
+				{
+					Samples: model.Samples{
+						&model.Sample{
+							Metric:    model.Metric{model.MetricNameLabel: "request_count", "some_label_name": "some_label_value", "quantile": "0.99"},
+							Value:     -42,
+							Timestamp: testTime,
+						},
+						&model.Sample{
+							Metric:    model.Metric{model.MetricNameLabel: "request_count", "some_label_name": "some_label_value", "quantile": "0.999"},
+							Value:     -84,
+							Timestamp: testTime,
+						},
+						&model.Sample{
+							Metric:    model.Metric{model.MetricNameLabel: "request_count", "another_label_name": "another_label_value", "quantile": "0.5"},
+							Value:     10,
+							Timestamp: testTime,
+						},
 					},
 				},
 			},
diff --git a/extraction/processor.go b/extraction/processor.go
index 89e8a6e..f7e0c29 100644
--- a/extraction/processor.go
+++ b/extraction/processor.go
@@ -30,7 +30,7 @@ type ProcessOptions struct {
 
 // Ingester consumes result streams in whatever way is desired by the user.
 type Ingester interface {
-	Ingest(model.Samples) error
+	Ingest(*Result) error
 }
 
 // Processor is responsible for decoding the actual message responses from
@@ -56,6 +56,42 @@ func labelSet(labels map[string]string) model.LabelSet {
 	return labelset
 }
 
+// Result encapsulates the outcome from processing samples from a source.
+type Result struct {
+	Err     error
+	Samples model.Samples
+}
+
+func (r *Result) equal(o *Result) bool {
+	if r == o {
+		return true
+	}
+
+	if r.Err != o.Err {
+		if r.Err == nil || o.Err == nil {
+			return false
+		}
+
+		if r.Err.Error() != o.Err.Error() {
+			return false
+		}
+	}
+
+	if len(r.Samples) != len(o.Samples) {
+		return false
+	}
+
+	for i, mine := range r.Samples {
+		other := o.Samples[i]
+
+		if !mine.Equal(other) {
+			return false
+		}
+	}
+
+	return true
+}
+
 // A basic interface only useful in testing contexts for dispensing the time
 // in a controlled manner.
 type instantProvider interface {
diff --git a/extraction/processor0_0_1.go b/extraction/processor0_0_1.go
index 9f8bddc..6c9760d 100644
--- a/extraction/processor0_0_1.go
+++ b/extraction/processor0_0_1.go
@@ -77,7 +77,11 @@ func (p *processor001) ProcessSingle(in io.Reader, out Ingester, o *ProcessOptio
 			case gauge001, counter001:
 				sampleValue, ok := value.Value.(float64)
 				if !ok {
-					return fmt.Errorf("could not convert value from %s %s to float64", entity, value)
+					err = fmt.Errorf("could not convert value from %s %s to float64", entity, value)
+					if err := out.Ingest(&Result{Err: err}); err != nil {
+						return err
+					}
+					continue
 				}
 
 				pendingSamples = append(pendingSamples, &model.Sample{
@@ -91,13 +95,21 @@ func (p *processor001) ProcessSingle(in io.Reader, out Ingester, o *ProcessOptio
 			case histogram001:
 				sampleValue, ok := value.Value.(map[string]interface{})
 				if !ok {
-					return fmt.Errorf("could not convert value from %q to a map[string]interface{}", value.Value)
+					err = fmt.Errorf("could not convert value from %q to a map[string]interface{}", value.Value)
+					if err := out.Ingest(&Result{Err: err}); err != nil {
+						return err
+					}
+					continue
 				}
 
 				for percentile, percentileValue := range sampleValue {
 					individualValue, ok := percentileValue.(float64)
 					if !ok {
-						return fmt.Errorf("could not convert value from %q to a float64", percentileValue)
+						err = fmt.Errorf("could not convert value from %q to a float64", percentileValue)
+						if err := out.Ingest(&Result{Err: err}); err != nil {
+							return err
+						}
+						continue
 					}
 
 					childMetric := make(map[model.LabelName]model.LabelValue, len(labels)+1)
@@ -120,7 +132,7 @@ func (p *processor001) ProcessSingle(in io.Reader, out Ingester, o *ProcessOptio
 		}
 	}
 	if len(pendingSamples) > 0 {
-		return out.Ingest(pendingSamples)
+		return out.Ingest(&Result{Samples: pendingSamples})
 	}
 
 	return nil
diff --git a/extraction/processor0_0_1_test.go b/extraction/processor0_0_1_test.go
index 3ffaa04..9ff530e 100644
--- a/extraction/processor0_0_1_test.go
+++ b/extraction/processor0_0_1_test.go
@@ -29,12 +29,12 @@ var test001Time = model.Now()
 
 type testProcessor001ProcessScenario struct {
 	in               string
-	expected, actual []model.Samples
+	expected, actual []*Result
 	err              error
 }
 
-func (s *testProcessor001ProcessScenario) Ingest(samples model.Samples) error {
-	s.actual = append(s.actual, samples)
+func (s *testProcessor001ProcessScenario) Ingest(r *Result) error {
+	s.actual = append(s.actual, r)
 	return nil
 }
 
@@ -56,10 +56,10 @@ func (s *testProcessor001ProcessScenario) test(t testing.TB, set int) {
 	}
 
 	for i, expected := range s.expected {
-		sort.Sort(s.actual[i])
-		sort.Sort(expected)
+		sort.Sort(s.actual[i].Samples)
+		sort.Sort(expected.Samples)
 
-		if !expected.Equal(s.actual[i]) {
+		if !expected.equal(s.actual[i]) {
 			t.Errorf("%d.%d. expected %s, got %s", set, i, expected, s.actual[i])
 		}
 	}
@@ -73,97 +73,101 @@ func testProcessor001Process(t testing.TB) {
 		},
 		{
 			in: "test0_0_1-0_0_2.json",
-			expected: []model.Samples{
-				model.Samples{
-					&model.Sample{
-						Metric:    model.Metric{"service": "zed", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
-						Value:     25,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"service": "bar", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
-						Value:     25,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"service": "foo", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
-						Value:     25,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     0.0459814091918713,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     78.48563317257356,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     15.890724674774395,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     0.0459814091918713,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     78.48563317257356,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     15.890724674774395,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     0.6120456642749681,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     97.31798360385088,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     84.63044031436561,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     1.355915069887731,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     109.89202084295582,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     160.21100853053224,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     1.772733213161236,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     109.99626121011262,
-						Timestamp: test001Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     172.49828748957728,
-						Timestamp: test001Time,
+			expected: []*Result{
+				{
+					Samples: model.Samples{
+						&model.Sample{
+							Metric:    model.Metric{"service": "zed", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
+							Value:     25,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"service": "bar", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
+							Value:     25,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"service": "foo", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
+							Value:     25,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     0.0459814091918713,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     78.48563317257356,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     15.890724674774395,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+
+							Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     0.0459814091918713,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     78.48563317257356,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     15.890724674774395,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     0.6120456642749681,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+
+							Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     97.31798360385088,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     84.63044031436561,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     1.355915069887731,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     109.89202084295582,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     160.21100853053224,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     1.772733213161236,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     109.99626121011262,
+							Timestamp: test001Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     172.49828748957728,
+							Timestamp: test001Time,
+						},
 					},
 				},
 			},
diff --git a/extraction/processor0_0_2.go b/extraction/processor0_0_2.go
index f1bb0b5..fbf660e 100644
--- a/extraction/processor0_0_2.go
+++ b/extraction/processor0_0_2.go
@@ -60,7 +60,11 @@ func (p *processor002) ProcessSingle(in io.Reader, out Ingester, o *ProcessOptio
 			var values []counter002
 
 			if err := json.Unmarshal(entity.Metric.Values, &values); err != nil {
-				return fmt.Errorf("could not extract %s value: %s", entity.Metric.Type, err)
+				err := fmt.Errorf("could not extract %s value: %s", entity.Metric.Type, err)
+				if err := out.Ingest(&Result{Err: err}); err != nil {
+					return err
+				}
+				continue
 			}
 
 			for _, counter := range values {
@@ -77,7 +81,11 @@ func (p *processor002) ProcessSingle(in io.Reader, out Ingester, o *ProcessOptio
 			var values []histogram002
 
 			if err := json.Unmarshal(entity.Metric.Values, &values); err != nil {
-				return fmt.Errorf("could not extract %s value: %s", entity.Metric.Type, err)
+				err := fmt.Errorf("could not extract %s value: %s", entity.Metric.Type, err)
+				if err := out.Ingest(&Result{Err: err}); err != nil {
+					return err
+				}
+				continue
 			}
 
 			for _, histogram := range values {
@@ -94,12 +102,15 @@ func (p *processor002) ProcessSingle(in io.Reader, out Ingester, o *ProcessOptio
 			}
 
 		default:
-			return fmt.Errorf("unknown metric type %q", entity.Metric.Type)
+			err := fmt.Errorf("unknown metric type %q", entity.Metric.Type)
+			if err := out.Ingest(&Result{Err: err}); err != nil {
+				return err
+			}
 		}
 	}
 
 	if len(pendingSamples) > 0 {
-		return out.Ingest(pendingSamples)
+		return out.Ingest(&Result{Samples: pendingSamples})
 	}
 
 	return nil
diff --git a/extraction/processor0_0_2_test.go b/extraction/processor0_0_2_test.go
index 6a7d458..4b7e592 100644
--- a/extraction/processor0_0_2_test.go
+++ b/extraction/processor0_0_2_test.go
@@ -30,12 +30,12 @@ var test002Time = model.Now()
 
 type testProcessor002ProcessScenario struct {
 	in               string
-	expected, actual []model.Samples
+	expected, actual []*Result
 	err              error
 }
 
-func (s *testProcessor002ProcessScenario) Ingest(samples model.Samples) error {
-	s.actual = append(s.actual, samples)
+func (s *testProcessor002ProcessScenario) Ingest(r *Result) error {
+	s.actual = append(s.actual, r)
 	return nil
 }
 
@@ -57,10 +57,10 @@ func (s *testProcessor002ProcessScenario) test(t testing.TB, set int) {
 	}
 
 	for i, expected := range s.expected {
-		sort.Sort(s.actual[i])
-		sort.Sort(expected)
+		sort.Sort(s.actual[i].Samples)
+		sort.Sort(expected.Samples)
 
-		if !expected.Equal(s.actual[i]) {
+		if !expected.equal(s.actual[i]) {
 			t.Fatalf("%d.%d. expected %s, got %s", set, i, expected, s.actual[i])
 		}
 	}
@@ -74,98 +74,101 @@ func testProcessor002Process(t testing.TB) {
 		},
 		{
 			in: "test0_0_1-0_0_2.json",
-			expected: []model.Samples{
-				model.Samples{
-					&model.Sample{
-						Metric:    model.Metric{"service": "zed", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
-						Value:     25,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"service": "bar", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
-						Value:     25,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"service": "foo", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
-						Value:     25,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     0.0459814091918713,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     78.48563317257356,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     15.890724674774395,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-
-						Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     0.0459814091918713,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     78.48563317257356,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     15.890724674774395,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     0.6120456642749681,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     97.31798360385088,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     84.63044031436561,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     1.355915069887731,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     109.89202084295582,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     160.21100853053224,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
-						Value:     1.772733213161236,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
-						Value:     109.99626121011262,
-						Timestamp: test002Time,
-					},
-					&model.Sample{
-						Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
-						Value:     172.49828748957728,
-						Timestamp: test002Time,
+			expected: []*Result{
+				{
+					Samples: model.Samples{
+						&model.Sample{
+							Metric:    model.Metric{"service": "zed", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
+							Value:     25,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"service": "bar", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
+							Value:     25,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"service": "foo", model.MetricNameLabel: "rpc_calls_total", "job": "batch_job"},
+							Value:     25,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     0.0459814091918713,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     78.48563317257356,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.010000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     15.890724674774395,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+
+							Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     0.0459814091918713,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     78.48563317257356,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.050000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     15.890724674774395,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     0.6120456642749681,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+
+							Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     97.31798360385088,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.500000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     84.63044031436561,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     1.355915069887731,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     109.89202084295582,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.900000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     160.21100853053224,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "zed"},
+							Value:     1.772733213161236,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "bar"},
+							Value:     109.99626121011262,
+							Timestamp: test002Time,
+						},
+						&model.Sample{
+							Metric:    model.Metric{"percentile": "0.990000", model.MetricNameLabel: "rpc_latency_microseconds", "service": "foo"},
+							Value:     172.49828748957728,
+							Timestamp: test002Time,
+						},
 					},
 				},
 			},
diff --git a/extraction/textprocessor_test.go b/extraction/textprocessor_test.go
index 86e37fe..e2c84ad 100644
--- a/extraction/textprocessor_test.go
+++ b/extraction/textprocessor_test.go
@@ -32,40 +32,44 @@ mf1{label="value1"} -3.14 123456
 mf1{label="value2"} 42
 mf2 4
 `
-	out = map[model.LabelValue]model.Samples{
-		"mf1": model.Samples{
-			&model.Sample{
-				Metric:    model.Metric{model.MetricNameLabel: "mf1", "label": "value1"},
-				Value:     -3.14,
-				Timestamp: 123456,
-			},
-			&model.Sample{
-				Metric:    model.Metric{model.MetricNameLabel: "mf1", "label": "value2"},
-				Value:     42,
-				Timestamp: ts,
+	out = map[model.LabelValue]*Result{
+		"mf1": {
+			Samples: model.Samples{
+				&model.Sample{
+					Metric:    model.Metric{model.MetricNameLabel: "mf1", "label": "value1"},
+					Value:     -3.14,
+					Timestamp: 123456,
+				},
+				&model.Sample{
+					Metric:    model.Metric{model.MetricNameLabel: "mf1", "label": "value2"},
+					Value:     42,
+					Timestamp: ts,
+				},
 			},
 		},
-		"mf2": model.Samples{
-			&model.Sample{
-				Metric:    model.Metric{model.MetricNameLabel: "mf2"},
-				Value:     3,
-				Timestamp: ts,
-			},
-			&model.Sample{
-				Metric:    model.Metric{model.MetricNameLabel: "mf2"},
-				Value:     4,
-				Timestamp: ts,
+		"mf2": {
+			Samples: model.Samples{
+				&model.Sample{
+					Metric:    model.Metric{model.MetricNameLabel: "mf2"},
+					Value:     3,
+					Timestamp: ts,
+				},
+				&model.Sample{
+					Metric:    model.Metric{model.MetricNameLabel: "mf2"},
+					Value:     4,
+					Timestamp: ts,
+				},
 			},
 		},
 	}
 )
 
 type testIngester struct {
-	results []model.Samples
+	results []*Result
 }
 
-func (i *testIngester) Ingest(s model.Samples) error {
-	i.results = append(i.results, s)
+func (i *testIngester) Ingest(r *Result) error {
+	i.results = append(i.results, r)
 	return nil
 }
 
@@ -84,16 +88,16 @@ func TestTextProcessor(t *testing.T) {
 		t.Fatalf("Expected length %d, got %d", expected, got)
 	}
 	for _, r := range ingester.results {
-		expected, ok := out[r[0].Metric[model.MetricNameLabel]]
+		expected, ok := out[r.Samples[0].Metric[model.MetricNameLabel]]
 		if !ok {
 			t.Fatalf(
 				"Unexpected metric name %q",
-				r[0].Metric[model.MetricNameLabel],
+				r.Samples[0].Metric[model.MetricNameLabel],
 			)
 		}
-		sort.Sort(expected)
-		sort.Sort(r)
-		if !expected.Equal(r) {
+		sort.Sort(expected.Samples)
+		sort.Sort(r.Samples)
+		if !expected.equal(r) {
 			t.Errorf("expected %s, got %s", expected, r)
 		}
 	}
diff --git a/model/sample.go b/model/sample.go
index 735a70b..4b0eb07 100644
--- a/model/sample.go
+++ b/model/sample.go
@@ -63,17 +63,3 @@ func (s Samples) Less(i, j int) bool {
 func (s Samples) Swap(i, j int) {
 	s[i], s[j] = s[j], s[i]
 }
-
-// Equal compares two sets of samples and returns true if they are equal.
-func (s Samples) Equal(o Samples) bool {
-	if len(s) != len(o) {
-		return false
-	}
-
-	for i, sample := range s {
-		if !sample.Equal(o[i]) {
-			return false
-		}
-	}
-	return true
-}
